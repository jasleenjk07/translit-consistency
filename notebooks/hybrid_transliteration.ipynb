{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8d6d704-2914-4a04-93b9-1518c62942e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jasleenkaur/Desktop/translit-consistency\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/jasleenkaur/Desktop/translit-consistency\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3638d74-55ee-470f-be4b-d0fb4b235c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from p2g import transliterate_p2g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29438c3f-f223-48f1-b0b6-5fd917a8617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import json\n",
    "import random\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bd94d76-bc34-475f-8921-a9e57b5e515e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d43db0cd-46e7-4234-b94b-558738362912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Pairs: 41044\n",
      "Train: 32835\n",
      "Val: 4104\n",
      "Test: 4105\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/processed/aligned_pairs_high_conf.json\", encoding = \"utf-8\") as f:\n",
    "    raw_pairs = json.load(f)\n",
    "\n",
    "print(\"Total Pairs:\", len(raw_pairs))\n",
    "\n",
    "pairs = [(en.lower(), hi) for en, hi, _ in raw_pairs]\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(pairs)\n",
    "\n",
    "n = len(pairs)\n",
    "train = pairs[:int(0.8 * n)]\n",
    "val = pairs[int(0.8 * n):int(0.9 * n)]\n",
    "test = pairs[int(0.9 * n):]\n",
    "\n",
    "print(\"Train:\", len(train))\n",
    "print(\"Val:\", len(val))\n",
    "print(\"Test:\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4dd5916e-de4e-40ad-ac9f-68d7b93e8441",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f713a6f-757c-441c-aa76-3d67365a691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx = 0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first = True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        outputs, (h, c) = self.lstm(emb)\n",
    "        return outputs, h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38ed20f6-a808-40d0-8c0c-fa396980842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.scale = 1.0 / (hidden_dim ** 0.5)\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        decoder_hidden: (B, H)\n",
    "        encoder_outputs: (B, src_len, H)\n",
    "        \"\"\"\n",
    "        # (B, src_len)\n",
    "        scores = torch.bmm(\n",
    "            encoder_outputs,\n",
    "            decoder_hidden.unsqueeze(2)\n",
    "        ).squeeze(2)\n",
    "\n",
    "        attn_weights = torch.softmax(scores * self.scale, dim=1)\n",
    "\n",
    "        # (B, H)\n",
    "        context = torch.bmm(\n",
    "            attn_weights.unsqueeze(1),\n",
    "            encoder_outputs\n",
    "        ).squeeze(1)\n",
    "\n",
    "        return context, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f3f9d98-f855-4737-8cfc-d2bf0129a128",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.attention = LuongAttention(hidden_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim + hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, h, c, encoder_outputs):\n",
    "        # x: (B, 1)\n",
    "        emb = self.embedding(x)  # (B, 1, E)\n",
    "\n",
    "        # Attention\n",
    "        context, _ = self.attention(h[-1], encoder_outputs)  # (B, H)\n",
    "        context = context.unsqueeze(1)  # (B, 1, H)\n",
    "\n",
    "        # LSTM\n",
    "        lstm_input = torch.cat([emb, context], dim=2)  # (B, 1, E+H)\n",
    "        output, (h, c) = self.lstm(lstm_input, (h, c))  # output: (B, 1, H)\n",
    "\n",
    "        logits = self.fc(output.squeeze(1))  # (B, vocab)\n",
    "        return logits, h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c920904-1e3b-4850-b410-40a409a165a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, pad_idx):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n",
    "        \"\"\"\n",
    "        src: (B, src_len)\n",
    "        tgt: (B, tgt_len)\n",
    "        \"\"\"\n",
    "        batch_size, tgt_len = tgt.shape\n",
    "        vocab_size = self.decoder.fc.out_features\n",
    "\n",
    "        outputs = torch.zeros(batch_size, tgt_len, vocab_size).to(src.device)\n",
    "\n",
    "        encoder_outputs, h, c = model.encoder(src)\n",
    "\n",
    "        input_tok = tgt[:, 0].unsqueeze(1)\n",
    "\n",
    "        for t in range(1, tgt_len):\n",
    "            logits, h, c = self.decoder(input_tok, h, c, encoder_outputs)\n",
    "            outputs[:, t] = logits\n",
    "\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = logits.argmax(1).unsqueeze(1)  \n",
    "\n",
    "            input_tok = tgt[:, t].unsqueeze(1) if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a8433988-0820-40e2-990f-b965d2662f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frozen Seq2Seq model loaded (best)\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"seq2seq_best.pt\", map_location=device)\n",
    "\n",
    "en_stoi = checkpoint[\"en_stoi\"]\n",
    "hi_stoi = checkpoint[\"hi_stoi\"]\n",
    "hi_itos = checkpoint[\"hi_itos\"]\n",
    "PAD = checkpoint[\"PAD\"]\n",
    "SOS = checkpoint[\"SOS\"]\n",
    "EOS = checkpoint[\"EOS\"]\n",
    "\n",
    "EMBED_DIM = checkpoint[\"EMBED_DIM\"]\n",
    "HIDDEN_DIM = checkpoint[\"HIDDEN_DIM\"]\n",
    "\n",
    "encoder = Encoder(len(en_stoi), EMBED_DIM, HIDDEN_DIM).to(device)\n",
    "decoder = Decoder(len(hi_stoi), EMBED_DIM, HIDDEN_DIM).to(device)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, hi_stoi[PAD]).to(device)\n",
    "\n",
    "model.load_state_dict(checkpoint[\"model_state\"])\n",
    "model.eval()\n",
    "\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "print(\"Frozen Seq2Seq model loaded (best)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7e73bf8-d4c2-4b0d-bea9-3ec93160f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_english(word):\n",
    "    return {\n",
    "        \"delhi\": \"dilli\",\n",
    "        \"bangalore\": \"bangalor\",\n",
    "        \"bengaluru\": \"bangalor\",\n",
    "        \"maharashta\": \"maharashtra\",\n",
    "    }.get(word.lower(), word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a132806-077a-40b7-bef9-4d20cc39ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(word, stoi):\n",
    "    if stoi is en_stoi:\n",
    "        word = normalize_english(word)\n",
    "    return [stoi[SOS]] + [stoi[c] for c in word] + [stoi[EOS]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "905c000c-fa6f-4e0d-8cd8-9e64c89d813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMON_FIXES = {\n",
    "    \"िि\": \"ि\",\n",
    "    \"ाा\": \"ा\",\n",
    "    \"ुु\": \"ु\",\n",
    "    \"ूू\": \"ू\",\n",
    "    \"ेे\": \"े\",\n",
    "    \"ोो\": \"ो\"\n",
    "}\n",
    "\n",
    "def normalize_hindi(text):\n",
    "    for b, g in COMMON_FIXES.items():\n",
    "        text = text.replace(b, g)\n",
    "    return text\n",
    "\n",
    "def postprocess_hindi(text):\n",
    "    # Collapse duplicated matras (िि → ि, etc.)\n",
    "    for m in [\"ि\", \"ी\", \"ा\", \"ु\", \"ू\", \"े\", \"ो\"]:\n",
    "        text = text.replace(m + m, m)\n",
    "\n",
    "    # Fix duplicated final consonant (ष्ट्ट → ष्ट)\n",
    "    if len(text) >= 2 and text[-1] == text[-2]:\n",
    "        text = text[:-1]\n",
    "\n",
    "    # PROTECT common Hindi suffixes\n",
    "    protected_suffixes = (\n",
    "        \"स्थान\", \"पुर\", \"नगर\", \"गंज\", \"गढ़\", \"पुरम\"\n",
    "    )\n",
    "    for suf in protected_suffixes:\n",
    "        if text.endswith(suf):\n",
    "            return text   # DO NOTHING further\n",
    "\n",
    "    # Trim hallucinated trailing junk ONLY if long\n",
    "    if len(text) >= 7:\n",
    "        # remove trailing vowels like \"जो\", \"यी\", \"ऊ\"\n",
    "        if text[-1] in {\"ो\", \"ू\", \"ी\"}:\n",
    "            text = text[:-1]\n",
    "\n",
    "        # remove trailing filler consonants\n",
    "        if text[-1] in {\"य\", \"र\"}:\n",
    "            text = text[:-1]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3f371a0-c763-470e-8efb-883a7becbaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def has_repetition_noise(text):\n",
    "    return bool(re.search(r\"(.)\\1\\1\", text))  # aaa / ललल"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68e59f55-5c67-4ed9-ab9f-ccd707952aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_transliterate(word):\n",
    "    seq_out = beam_transliterate(model, word)\n",
    "\n",
    "    # Only catastrophic failures fall back to P2G\n",
    "    if (\n",
    "        len(seq_out) <= 2 or\n",
    "        seq_out.endswith(\"्\") or\n",
    "        seq_out.startswith((\"ि\", \"ी\")) or\n",
    "        len(seq_out) > 2 * len(word)\n",
    "    ):\n",
    "        return transliterate_p2g(word)\n",
    "\n",
    "    # Otherwise trust Seq2Seq\n",
    "    return seq_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c9811d6-6451-4ec5-950b-743f762e1e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_transliterate(model, word, beam_width=3, max_len=40):\n",
    "    model.eval()\n",
    "\n",
    "    src = torch.tensor([encode(word.lower(), en_stoi)], dtype=torch.long).to(device)\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, h, c = model.encoder(src)\n",
    "\n",
    "    beams = [([hi_stoi[SOS]], 0.0, h, c)]\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        new_beams = []\n",
    "        for seq, score, h, c in beams:\n",
    "            if seq[-1] == hi_stoi[EOS]:\n",
    "                new_beams.append((seq, score, h, c))\n",
    "                continue\n",
    "\n",
    "            input_tok = torch.tensor([[seq[-1]]], device=device)\n",
    "            with torch.no_grad():\n",
    "                logits, h_new, c_new = model.decoder(input_tok, h, c, encoder_outputs)\n",
    "\n",
    "            log_probs = torch.log_softmax(logits[0], dim=-1)\n",
    "            topk = torch.topk(log_probs, beam_width)\n",
    "\n",
    "            for idx, val in zip(topk.indices, topk.values):\n",
    "                new_beams.append(\n",
    "                    (seq + [idx.item()], score + val.item(), h_new, c_new)\n",
    "                )\n",
    "\n",
    "        beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_width]\n",
    "        if all(seq[-1] == hi_stoi[EOS] for seq, _, _, _ in beams):\n",
    "            break\n",
    "\n",
    "    best = beams[0][0]\n",
    "    out = \"\".join(\n",
    "        hi_itos[i] for i in best\n",
    "        if i not in {hi_stoi[SOS], hi_stoi[EOS], hi_stoi[PAD]}\n",
    "    )\n",
    "    out = normalize_hindi(out)\n",
    "    out = postprocess_hindi(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6999221-3d65-4e2c-82b6-6cd9a666178e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delhi → दिल्ली\n",
      "Kolkata → कोलकत\n",
      "Bangalore → बंगलोरो\n",
      "Rajasthan → राजस्थान\n",
      "Chandrakala → चं्दकरलाल\n",
      "Vishnupuram → विषुणपुरम\n",
      "Maharashtra → माहाष्ट्र\n",
      "Kaveri → केवीरी\n"
     ]
    }
   ],
   "source": [
    "tests = [\n",
    "    \"Delhi\", \"Kolkata\", \"Bangalore\", \"Rajasthan\",\n",
    "    \"Chandrakala\", \"Vishnupuram\", \"Maharashtra\", \"Kaveri\"\n",
    "]\n",
    "\n",
    "for w in tests:\n",
    "    print(w, \"→\", hybrid_transliterate(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a81328af-a352-45e7-a6f2-e99810c77336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Char Accuracy: 0.4795810227060876\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/processed/aligned_pairs_high_conf.json\", encoding=\"utf-8\") as f:\n",
    "    raw_pairs = json.load(f)\n",
    "\n",
    "def char_accuracy(pred, gold):\n",
    "    m = min(len(pred), len(gold))\n",
    "    return sum(pred[i] == gold[i] for i in range(m)) / max(len(gold), 1)\n",
    "\n",
    "acc = []\n",
    "for en, hi, _ in raw_pairs:\n",
    "    pred = hybrid_transliterate(en)\n",
    "    acc.append(char_accuracy(pred, hi))\n",
    "\n",
    "print(\"Hybrid Char Accuracy:\", sum(acc) / len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6e63822-9086-4422-87f4-8b4bed7d6cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_hybrid(data, limit=None):\n",
    "    \"\"\"\n",
    "    data: list of (en, hi) OR (en, hi, conf)\n",
    "    limit: optimal int to evaluate on subset (for speed)\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "\n",
    "    for i, item in enumerate(data):\n",
    "        if limit and i >= limit:\n",
    "            break\n",
    "\n",
    "        en = item[0]\n",
    "        hi = item[1]\n",
    "\n",
    "        pred = hybrid_transliterate(en)\n",
    "        scores.append(char_accuracy(pred, hi))\n",
    "\n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6682128e-cda6-4e7c-9523-9079edfeeaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Train: 48.55 %\n",
      "Hybrid Val: 48.62 %\n",
      "Hybrid Test: 47.38 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Hybrid Train:\",\n",
    "      round(evaluate_hybrid(train, limit=2000) * 100, 2), \"%\")\n",
    "\n",
    "print(\"Hybrid Val:\",\n",
    "      round(evaluate_hybrid(val) * 100, 2), \"%\")\n",
    "\n",
    "print(\"Hybrid Test:\",\n",
    "      round(evaluate_hybrid(test) * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e48debb2-a817-43af-840f-2f7f576d8d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_system(data, predict_fn, limit=None):\n",
    "    scores = []\n",
    "\n",
    "    for i, (en, hi) in enumerate(data):\n",
    "        if limit and i >= limit:\n",
    "            break\n",
    "\n",
    "        pred = predict_fn(en)\n",
    "        scores.append(char_accuracy(pred, hi))\n",
    "\n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d2a10c3-c4c8-4f87-812c-e6a0de2f14e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq Val: 0.4939393702734339\n",
      "P2G Val: 0.33677252125717\n",
      "Hybrid Val: 0.48618695915844923\n"
     ]
    }
   ],
   "source": [
    "print(\"Seq2Seq Val:\", evaluate_system(val, lambda w: beam_transliterate(model, w)))\n",
    "print(\"P2G Val:\", evaluate_system(val, transliterate_p2g))\n",
    "print(\"Hybrid Val:\", evaluate_system(val, hybrid_transliterate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6ea13b4e-6d60-4e52-aed4-d32fb7dd14cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_type(pred, gold):\n",
    "    if len(pred) < len(gold):\n",
    "        return \"UNDER\"\n",
    "    if len(pred) > len(gold):\n",
    "        return \"OVER\"\n",
    "    if \"्\" in pred and \"्\" not in gold:\n",
    "        return \"HALANT\"\n",
    "    return \"OTHER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c530dcc6-bf94-434e-a38d-7a3f6180b15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def analyze_errors(data, limit=1000):\n",
    "    counter = Counter()\n",
    "\n",
    "    for i, (en, hi) in enumerate(data):\n",
    "        if i >= limit:\n",
    "            break\n",
    "        pred = hybrid_transliterate(en)\n",
    "        counter[error_type(pred, hi)] += 1\n",
    "\n",
    "    total = sum(counter.values())\n",
    "    for k in counter:\n",
    "        counter[k] = round(counter[k] / total * 100, 2)\n",
    "\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d87c56d-729e-456b-b333-d273a45114d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Error Distribution (Val):\n",
      "Counter({'OVER': 36.7, 'OTHER': 35.2, 'UNDER': 27.3, 'HALANT': 0.8})\n"
     ]
    }
   ],
   "source": [
    "print(\"Hybrid Error Distribution (Val):\")\n",
    "print(analyze_errors(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c7e9751b-a0d9-4bce-ac3f-b4f9806ec418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': 'Delhi', 'seq_out': 'दिल्ली', 'p2g_out': 'दिली', 'chosen': 'SEQ2SEQ'}\n",
      "{'word': 'Kolkata', 'seq_out': 'कोलकत', 'p2g_out': 'कोलकात', 'chosen': 'SEQ2SEQ'}\n",
      "{'word': 'Rajasthan', 'seq_out': 'राजस्थान', 'p2g_out': 'रझअशअन्', 'chosen': 'SEQ2SEQ'}\n",
      "{'word': 'Bangalore', 'seq_out': 'बंगलोरो', 'p2g_out': 'बैंगअलोर्', 'chosen': 'SEQ2SEQ'}\n",
      "{'word': 'Shanghai', 'seq_out': 'शाघई', 'p2g_out': 'शैंघ्', 'chosen': 'SEQ2SEQ'}\n",
      "{'word': 'Sukla', 'seq_out': 'सुकला', 'p2g_out': 'सअकल', 'chosen': 'SEQ2SEQ'}\n"
     ]
    }
   ],
   "source": [
    "def hybrid_debug(word):\n",
    "    seq_out = beam_transliterate(model, word)\n",
    "    p2g_out = transliterate_p2g(word)\n",
    "\n",
    "    chosen = \"SEQ2SEQ\"\n",
    "\n",
    "    if (\n",
    "        len(seq_out) <= 2 or\n",
    "        seq_out.count(\"्\") > 3 or\n",
    "        \"ङ\" in seq_out or\n",
    "        seq_out.endswith((\"य\", \"र\")) or\n",
    "        seq_out in {\"शाघ\", \"बान्गोल\"} or\n",
    "        len(seq_out) - len(word) >= 4\n",
    "    ):\n",
    "        chosen = \"P2G\"\n",
    "\n",
    "    return {\n",
    "        \"word\": word,\n",
    "        \"seq_out\": seq_out,\n",
    "        \"p2g_out\": p2g_out,\n",
    "        \"chosen\": chosen\n",
    "    }\n",
    "\n",
    "for w in [\"Delhi\", \"Kolkata\", \"Rajasthan\", \"Bangalore\", \"Shanghai\", \"Sukla\"]:\n",
    "    print(hybrid_debug(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0c82841c-2ee5-40ab-adb0-6bbe8f0b06f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('insulin', 'इन्सुलिन', 'निसुलीन')\n",
      "('sevak', 'सेवा', 'कावक')\n",
      "('kamapala', 'कामपाल', 'कामपलाल')\n",
      "('brahmapurana', 'ब्रह्मपुराण', 'ब्रहमपुराण')\n",
      "('ananta', 'अनन्त', 'अन्तन')\n",
      "('udaygiri', 'उदयगिरी', 'उदयगिरिरि')\n",
      "('brhatkatha', 'बृहत्कथा', 'भीतकथाट')\n",
      "('visva-bharati', 'विश्वभारती', 'विष्भारतति')\n",
      "('jaaye', 'जाये', 'जयेय')\n",
      "('jodhpuri', 'जोधपुरी', 'जोधपु')\n",
      "('chellattamman', 'चेल्लत्तम्मन', 'चेलत्तम्तम्मा')\n",
      "('tirhio', 'टिरहिओ', 'थिरोहि')\n",
      "('bahujan', 'बहुजन', 'बाजुंजन')\n",
      "('make', 'मौके', 'केके')\n",
      "('alur', 'अलुर', 'लुरुर')\n",
      "('maulaha', 'मौलाना', 'मौलाहा')\n",
      "('kanya - kumari', 'कन्याकुमारी', 'क्याकुमामा')\n",
      "('arthantaranyasa', 'अर्थातरन्यास', 'अर्तनातरण्यश')\n",
      "('mudrikalu', 'मुद्रिकालु', 'मुदिकलालु')\n",
      "('pandora', 'पंडोरा', 'पंदोरो')\n"
     ]
    }
   ],
   "source": [
    "def collect_errors(data, limit=200):\n",
    "    errors = []\n",
    "    for en, hi in data[:limit]:\n",
    "        pred = hybrid_transliterate(en)\n",
    "        if pred != hi:\n",
    "            errors.append((en, hi, pred))\n",
    "    return errors\n",
    "\n",
    "errors = collect_errors(val, 200)\n",
    "\n",
    "for e in errors[:20]:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "31cfa64b-dca8-4761-813e-9d0079921db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bhaina → भीना | gold: भइना\n",
      "Sethna → सेथना | gold: सेठना\n",
      "Hallada → लाददाला | gold: हल्लद\n",
      "Shikshan → शिक्षण | gold: शिक्षण\n",
      "tipu → तिपु | gold: टीपू\n",
      "Aghoresvara → अगोरेश्व | gold: अघोरेश्वर\n",
      "Incapacity → विपाचचिट्ट | gold: ईन्चपचिट्य्\n",
      "Hasbi → शबीबी | gold: हस्बी\n",
      "Lokasangraha → कोगसंंगर्श | gold: लोकसंग्रह\n",
      "Limaye → लिमयेय | gold: लिमये\n",
      "Nelumbo → नुम्बोम्ब | gold: नेलम्बो\n",
      "Ashi → ैषि | gold: काशी\n",
      "Chughtai → चुतगाटै | gold: चुगताई\n",
      "Hebron → वेबोरोन | gold: हेब्रोन\n",
      "Panchgavya → पंचवव््यव | gold: पंचगव्य\n",
      "Dalma → दम्ममा | gold: डालमा\n",
      "Kalapani → कापापनि | gold: कालापानी\n",
      "Gurubani → गुरुबान | gold: गुरबानी\n",
      "Gujjar → गुजजर | gold: गुज्जर\n",
      "Setubandha → शेतुबन्धन | gold: सेतुबंध\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "sample = random.sample(raw_pairs, 200)\n",
    "for en, hi, _ in sample[:20]:\n",
    "    print(en, \"→\", hybrid_transliterate(en), \"| gold:\", hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd153060-b04b-40d8-a770-bd2173564885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (p2g)",
   "language": "python",
   "name": "p2g"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
