{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53b1eb2a-e453-4367-962b-40a86fd4c64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total raw pairs: 41044\n"
     ]
    }
   ],
   "source": [
    "import os, json, random\n",
    "\n",
    "PROJECT_ROOT = \"/Users/jasleenkaur/Desktop/translit-consistency\"\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "with open(\"data/processed/aligned_pairs_high_conf.json\", encoding=\"utf-8\") as f:\n",
    "    raw_pairs = json.load(f)\n",
    "\n",
    "print(\"Total raw pairs:\", len(raw_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b4195cb-15f0-469b-9559-adedec47254f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered pairs: 40982\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def is_valid_pair(en, hi):\n",
    "    # Hindi must be Devanagari only\n",
    "    if not re.fullmatch(r\"[ऀ-ॿ।]+\", hi):\n",
    "        return False\n",
    "\n",
    "    # Avoid extreme length mismatch\n",
    "    if abs(len(en) - len(hi)) > 10:\n",
    "        return False\n",
    "\n",
    "    # Too many halants = noisy\n",
    "    if hi.count(\"्\") > 3:\n",
    "        return False\n",
    "\n",
    "    # Remove junk repetitions\n",
    "    if len(hi) - len(set(hi)) > 6:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "pairs = []\n",
    "for en, hi, _ in raw_pairs:\n",
    "    en = en.lower()\n",
    "    if is_valid_pair(en, hi):\n",
    "        pairs.append((en, hi))\n",
    "\n",
    "print(\"Filtered pairs:\", len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b36443ca-726f-4d45-8ab5-76fae4f82d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  32785\n",
      "Val:  4098\n",
      "Test:  4099\n"
     ]
    }
   ],
   "source": [
    "random.seed(42)\n",
    "random.shuffle(pairs)\n",
    "\n",
    "n = len(pairs)\n",
    "train = pairs[:int(0.8 * n)]\n",
    "val = pairs[int(0.8 * n):int(0.9 * n)]\n",
    "test = pairs[int(0.9 * n):]\n",
    "\n",
    "print(\"Train: \", len(train))\n",
    "print(\"Val: \", len(val))\n",
    "print(\"Test: \", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8be4dd40-1e27-41a9-8523-bde3818a7425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English chars:  61\n",
      "Hindi chars:  80\n"
     ]
    }
   ],
   "source": [
    "def build_char_set(words):\n",
    "    chars = set()\n",
    "    for w in words:\n",
    "        chars.update(w)\n",
    "    return sorted(chars)\n",
    "\n",
    "en_words = [en for en, hi in pairs]\n",
    "hi_words = [hi for en, hi in pairs]\n",
    "\n",
    "en_chars = build_char_set(en_words)\n",
    "hi_chars = build_char_set(hi_words)\n",
    "\n",
    "print(\"English chars: \", len(en_chars))\n",
    "print(\"Hindi chars: \", len(hi_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10cf948f-3df0-4f80-9689-cc9d99faaa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = \"<pad>\"\n",
    "SOS = \"<s>\"\n",
    "EOS = \"</s>\"\n",
    "\n",
    "def build_vocab_with_tokens(chars):\n",
    "    vocab = [PAD, SOS, EOS] + chars\n",
    "    stoi = {c: i for i, c in enumerate(vocab)}\n",
    "    itos = {i: c for c, i in stoi.items()}\n",
    "    return vocab, stoi, itos\n",
    "\n",
    "en_vocab, en_stoi, en_itos = build_vocab_with_tokens(en_chars)\n",
    "hi_vocab, hi_stoi, hi_itos = build_vocab_with_tokens(hi_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eb895fb-79ba-41af-98a4-4a9327c7427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_english(word):\n",
    "    return {\n",
    "        \"delhi\": \"dilli\",\n",
    "        \"bangalore\": \"bangalor\",\n",
    "        \"bengaluru\": \"bangalor\",\n",
    "        \"maharashta\": \"maharashtra\",\n",
    "    }.get(word.lower(), word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81309475-2886-4da8-80cb-a8db0e64e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(word, stoi):\n",
    "    if stoi is en_stoi:\n",
    "        word = normalize_english(word)\n",
    "    return [stoi[SOS]] + [stoi[c] for c in word] + [stoi[EOS]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9232e757-fc72-44da-8a4a-23e3bfcf8be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded train example:\n",
      "([1, 39, 21, 40, 45, 21, 27, 38, 28, 21, 2], [1, 51, 34, 67, 44, 54, 21, 67, 45, 52, 2])\n"
     ]
    }
   ],
   "source": [
    "train_enc = [(encode(en, en_stoi), encode(hi, hi_stoi)) for en, hi in train]\n",
    "val_enc   = [(encode(en, en_stoi), encode(hi, hi_stoi)) for en, hi in val]\n",
    "test_enc  = [(encode(en, en_stoi), encode(hi, hi_stoi)) for en, hi in test]\n",
    "\n",
    "print(\"Encoded train example:\")\n",
    "print(train_enc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6d3bbf1-ba09-4738-9157-d27754bfd80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(seq, max_len, pad_id):\n",
    "    return seq + [pad_id] * (max_len - len(seq))\n",
    "\n",
    "max_en_len = max(len(x[0]) for x in train_enc)\n",
    "max_hi_len = max(len(x[1]) for x in train_enc)\n",
    "\n",
    "train_pad = [\n",
    "    (pad(src, max_en_len, en_stoi[PAD]),\n",
    "     pad(tgt, max_hi_len, hi_stoi[PAD]))\n",
    "    for src, tgt in train_enc\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9a86076-b402-4b50-bc9f-018418195d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c52ca9d-b3a4-4709-8a20-c4af504eec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_src = torch.tensor(\n",
    "    [src for src, tgt in train_pad],\n",
    "    dtype = torch.long\n",
    ").to(device)\n",
    "\n",
    "train_tgt = torch.tensor(\n",
    "    [tgt for src, tgt in train_pad],\n",
    "    dtype = torch.long\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2be21d12-61d5-475c-81aa-66e890f76162",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx = 0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first = True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        outputs, (h, c) = self.lstm(emb)\n",
    "        return outputs, h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "febec7f9-482d-4b32-8eb6-014888a77616",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.scale = 1.0 / (hidden_dim ** 0.5)\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        decoder_hidden: (B, H)\n",
    "        encoder_outputs: (B, src_len, H)\n",
    "        \"\"\"\n",
    "        # (B, src_len)\n",
    "        scores = torch.bmm(\n",
    "            encoder_outputs,\n",
    "            decoder_hidden.unsqueeze(2)\n",
    "        ).squeeze(2)\n",
    "\n",
    "        attn_weights = torch.softmax(scores * self.scale, dim=1)\n",
    "\n",
    "        # (B, H)\n",
    "        context = torch.bmm(\n",
    "            attn_weights.unsqueeze(1),\n",
    "            encoder_outputs\n",
    "        ).squeeze(1)\n",
    "\n",
    "        return context, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02ebacce-8ef2-4ef8-8cc7-a290e8f79469",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.attention = LuongAttention(hidden_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim + hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, h, c, encoder_outputs):\n",
    "        # x: (B, 1)\n",
    "        emb = self.embedding(x)  # (B, 1, E)\n",
    "\n",
    "        # Attention\n",
    "        context, _ = self.attention(h[-1], encoder_outputs)  # (B, H)\n",
    "        context = context.unsqueeze(1)  # (B, 1, H)\n",
    "\n",
    "        # LSTM\n",
    "        lstm_input = torch.cat([emb, context], dim=2)  # (B, 1, E+H)\n",
    "        output, (h, c) = self.lstm(lstm_input, (h, c))  # output: (B, 1, H)\n",
    "\n",
    "        logits = self.fc(output.squeeze(1))  # (B, vocab)\n",
    "        return logits, h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3d9a592-b8cc-46a3-a3d5-983d548f14ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, pad_idx):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n",
    "        \"\"\"\n",
    "        src: (B, src_len)\n",
    "        tgt: (B, tgt_len)\n",
    "        \"\"\"\n",
    "        batch_size, tgt_len = tgt.shape\n",
    "        vocab_size = self.decoder.fc.out_features\n",
    "\n",
    "        outputs = torch.zeros(batch_size, tgt_len, vocab_size).to(src.device)\n",
    "\n",
    "        encoder_outputs, h, c = self.encoder(src)\n",
    "\n",
    "        input_tok = tgt[:, 0].unsqueeze(1)\n",
    "\n",
    "        for t in range(1, tgt_len):\n",
    "            logits, h, c = self.decoder(input_tok, h, c, encoder_outputs)\n",
    "            outputs[:, t] = logits\n",
    "\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = logits.argmax(1).unsqueeze(1)  \n",
    "\n",
    "            input_tok = tgt[:, t].unsqueeze(1) if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46160d39-82d7-4502-a41d-d318a7b21ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "\n",
    "encoder = Encoder(len(en_vocab), EMBED_DIM, HIDDEN_DIM).to(device)\n",
    "decoder = Decoder(len(hi_vocab), EMBED_DIM, HIDDEN_DIM).to(device)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, hi_stoi[PAD]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21365877-68a0-4cb7-9464-68e59b0f9236",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = 0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9ec3a4d-8f83-4589-804c-62434fe2e129",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(\n",
    "    ignore_index=hi_stoi[PAD],\n",
    "    label_smoothing=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bb0f8cc-c70d-4c6c-9503-b3c947cffc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_dataset(enc_data, max_en_len, max_hi_len):\n",
    "    return[\n",
    "        (\n",
    "            pad(src, max_en_len, en_stoi[PAD]),\n",
    "            pad(tgt, max_hi_len, hi_stoi[PAD])\n",
    "        )\n",
    "        for src, tgt in enc_data\n",
    "    ]\n",
    "\n",
    "val_pad = pad_dataset(val_enc, max_en_len, max_hi_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d5e0168-a357-4a48-869c-b59eabe1c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 60\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def train_epoch(model, data, optimizer, criterion, teacher_forcing_ratio):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    random.shuffle(data)\n",
    "\n",
    "    for i in range(0, len(data), BATCH_SIZE):\n",
    "        batch = data[i:i+BATCH_SIZE]\n",
    "        src = torch.tensor([x[0] for x in batch], dtype=torch.long).to(device)\n",
    "        tgt = torch.tensor([x[1] for x in batch], dtype=torch.long).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, tgt, teacher_forcing_ratio=teacher_forcing_ratio)\n",
    "\n",
    "        loss = criterion(\n",
    "            output[:, 1:].reshape(-1, output.size(-1)),\n",
    "            tgt[:, 1:].reshape(-1)\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / (len(data) // BATCH_SIZE + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ee3f1f8-59dc-49ec-a3db-7fb8b7654c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data), BATCH_SIZE):\n",
    "            batch = data[i:i+BATCH_SIZE]\n",
    "            src = torch.tensor([x[0] for x in batch], dtype=torch.long).to(device)\n",
    "            tgt = torch.tensor([x[1] for x in batch], dtype=torch.long).to(device)\n",
    "\n",
    "            output = model(src, tgt, teacher_forcing_ratio=0.0)\n",
    "\n",
    "            loss = criterion(\n",
    "                output[:, 1:].reshape(-1, output.size(-1)),\n",
    "                tgt[:, 1:].reshape(-1)\n",
    "            )\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / (len(data) // BATCH_SIZE + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33f9a847-a1cc-40da-87ca-7e9920392d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMON_FIXES = {\n",
    "    \"िि\": \"ि\",\n",
    "    \"ाा\": \"ा\",\n",
    "    \"ुु\": \"ु\",\n",
    "    \"ूू\": \"ू\",\n",
    "    \"ेे\": \"े\",\n",
    "    \"ोो\": \"ो\"\n",
    "}\n",
    "\n",
    "def normalize_hindi(text):\n",
    "    for b, g in COMMON_FIXES.items():\n",
    "        text = text.replace(b, g)\n",
    "    return text\n",
    "\n",
    "def postprocess_hindi(text):\n",
    "    # Collapse duplicated matras (िि → ि, etc.)\n",
    "    for m in [\"ि\", \"ी\", \"ा\", \"ु\", \"ू\", \"े\", \"ो\"]:\n",
    "        text = text.replace(m + m, m)\n",
    "\n",
    "    # Fix duplicated final consonant (ष्ट्ट → ष्ट)\n",
    "    if len(text) >= 2 and text[-1] == text[-2]:\n",
    "        text = text[:-1]\n",
    "\n",
    "    # PROTECT common Hindi suffixes\n",
    "    protected_suffixes = (\n",
    "        \"स्थान\", \"पुर\", \"नगर\", \"गंज\", \"गढ़\", \"पुरम\"\n",
    "    )\n",
    "    for suf in protected_suffixes:\n",
    "        if text.endswith(suf):\n",
    "            return text   # DO NOTHING further\n",
    "\n",
    "    # Trim hallucinated trailing junk ONLY if long\n",
    "    if len(text) >= 7:\n",
    "        # remove trailing vowels like \"जो\", \"यी\", \"ऊ\"\n",
    "        if text[-1] in {\"ो\", \"ू\", \"ी\"}:\n",
    "            text = text[:-1]\n",
    "\n",
    "        # remove trailing filler consonants\n",
    "        if text[-1] in {\"य\", \"र\"}:\n",
    "            text = text[:-1]\n",
    "\n",
    "    return text\n",
    "\n",
    "def fix_common_seq2seq_errors(text):\n",
    "    # Remove hallucinated trailing syllables\n",
    "    if text.endswith(\"का\") and len(text) > 5:\n",
    "        text = text[:-2]\n",
    "\n",
    "    # Fix vowel echo (रीरे → री, रिरे → री)\n",
    "    text = text.replace(\"रीरे\", \"री\")\n",
    "    text = text.replace(\"रिरे\", \"री\")\n",
    "\n",
    "    # Fix double syllable drift (ल्ली → ली)\n",
    "    text = text.replace(\"ल्लि\", \"ल्ली\")\n",
    "    text = text.replace(\"मिल्लि\", \"दिल्ली\")\n",
    "\n",
    "    # Remove dangling halant at end\n",
    "    if text.endswith(\"्\"):\n",
    "        text = text[:-1]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0511070b-22de-448b-bfd5-0b6292648aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_accuracy(pred, gold):\n",
    "    correct = 0\n",
    "    total = max(len(pred), len(gold))\n",
    "\n",
    "    for p, g in zip(pred, gold):\n",
    "        if p == g:\n",
    "            correct += 1\n",
    "\n",
    "    return correct / total if total > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a1bdc01-2661-41de-a763-b67bb2738251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_transliterate(model, word, beam_width=4, max_len=40):\n",
    "    model.eval()\n",
    "\n",
    "    src = torch.tensor([encode(word.lower(), en_stoi)], dtype=torch.long).to(device)\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, h, c = model.encoder(src)\n",
    "\n",
    "    beams = [([hi_stoi[SOS]], 0.0, h, c)]\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        new_beams = []\n",
    "        for seq, score, h, c in beams:\n",
    "            if seq[-1] == hi_stoi[EOS]:\n",
    "                new_beams.append((seq, score, h, c))\n",
    "                continue\n",
    "\n",
    "            input_tok = torch.tensor([[seq[-1]]], device=device)\n",
    "            with torch.no_grad():\n",
    "                logits, h_new, c_new = model.decoder(input_tok, h, c, encoder_outputs)\n",
    "\n",
    "            log_probs = torch.log_softmax(logits[0], dim=-1)\n",
    "            topk = torch.topk(log_probs, beam_width)\n",
    "\n",
    "            for idx, val in zip(topk.indices, topk.values):\n",
    "                next_char = hi_itos[idx.item()]\n",
    "\n",
    "                penalty = 0.0\n",
    "                if seq.count(idx.item()) >= 2:\n",
    "                    penalty = 1.5\n",
    "                    \n",
    "                new_beams.append(\n",
    "                    (seq + [idx.item()],score + val.item() - penalty,h_new,c_new)\n",
    "                )\n",
    "\n",
    "        beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_width]\n",
    "        if all(seq[-1] == hi_stoi[EOS] for seq, _, _, _ in beams):\n",
    "            break\n",
    "\n",
    "    best = beams[0][0]\n",
    "    out = \"\".join(\n",
    "        hi_itos[i] for i in best\n",
    "        if i not in {hi_stoi[SOS], hi_stoi[EOS], hi_stoi[PAD]}\n",
    "    )\n",
    "    out = normalize_hindi(out)\n",
    "    out = postprocess_hindi(out)\n",
    "    out = fix_common_seq2seq_errors(out)\n",
    "\n",
    "    if len(out) > 2 * len(word):\n",
    "        out = out[:2 * len(word)]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50bcda07-97c5-4d0b-b293-355ecab2b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_char_accuracy(model, data, limit=None):\n",
    "    scores = []\n",
    "\n",
    "    for i, (en, hi) in enumerate(data):\n",
    "        if limit and i >= limit:\n",
    "            break\n",
    "\n",
    "        pred = beam_transliterate(model, en)\n",
    "        scores.append(char_accuracy(pred, hi))\n",
    "\n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de403e8f-0a9e-4145-a7f5-0562d25f0b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Loss: 1.4436\n",
      "Val Char Accuracy: 43.85%\n",
      "New best model saved\n",
      "----------------------------------------\n",
      "Epoch 2\n",
      "Train Loss: 1.4005\n",
      "Val Char Accuracy: 42.49%\n",
      "No improvement (1/6)\n",
      "----------------------------------------\n",
      "Epoch 3\n",
      "Train Loss: 1.3678\n",
      "Val Char Accuracy: 44.83%\n",
      "New best model saved\n",
      "----------------------------------------\n",
      "Epoch 4\n",
      "Train Loss: 1.3354\n",
      "Val Char Accuracy: 45.25%\n",
      "New best model saved\n",
      "----------------------------------------\n",
      "Epoch 5\n",
      "Train Loss: 1.3108\n",
      "Val Char Accuracy: 45.03%\n",
      "No improvement (1/6)\n",
      "----------------------------------------\n",
      "Epoch 6\n",
      "Train Loss: 1.2949\n",
      "Val Char Accuracy: 45.11%\n",
      "No improvement (2/6)\n",
      "----------------------------------------\n",
      "Epoch 7\n",
      "Train Loss: 1.2754\n",
      "Val Char Accuracy: 43.66%\n",
      "No improvement (3/6)\n",
      "----------------------------------------\n",
      "Epoch 8\n",
      "Train Loss: 1.2556\n",
      "Val Char Accuracy: 44.25%\n",
      "No improvement (4/6)\n",
      "----------------------------------------\n",
      "Epoch 9\n",
      "Train Loss: 1.2398\n",
      "Val Char Accuracy: 45.29%\n",
      "New best model saved\n",
      "----------------------------------------\n",
      "Epoch 10\n",
      "Train Loss: 1.2217\n",
      "Val Char Accuracy: 44.38%\n",
      "No improvement (1/6)\n",
      "----------------------------------------\n",
      "Epoch 11\n",
      "Train Loss: 1.2067\n",
      "Val Char Accuracy: 43.85%\n",
      "No improvement (2/6)\n",
      "----------------------------------------\n",
      "Epoch 12\n",
      "Train Loss: 1.1896\n",
      "Val Char Accuracy: 43.22%\n",
      "No improvement (3/6)\n",
      "----------------------------------------\n",
      "Epoch 13\n",
      "Train Loss: 1.1719\n",
      "Val Char Accuracy: 44.34%\n",
      "No improvement (4/6)\n",
      "----------------------------------------\n",
      "Epoch 14\n",
      "Train Loss: 1.1599\n",
      "Val Char Accuracy: 44.18%\n",
      "No improvement (5/6)\n",
      "----------------------------------------\n",
      "Epoch 15\n",
      "Train Loss: 1.1422\n",
      "Val Char Accuracy: 43.95%\n",
      "No improvement (6/6)\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "# for epoch in range(EPOCHS):\n",
    "#     teacher_forcing_ratio = max(0.25, 0.6 * (0.97 ** epoch))\n",
    "#     # teacher_forcing_ratio = 0.5\n",
    "#     train_loss = train_epoch(model, train_pad, optimizer, criterion, teacher_forcing_ratio)\n",
    "#     val_loss = evaluate(model, val_pad, criterion)\n",
    "\n",
    "#     print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "#     print(f\"Train Loss: {train_loss:.4f}\")\n",
    "#     print(f\"Val Loss: {val_loss:.4f}\")\n",
    "#     print(\"-\" * 40)\n",
    "num_epochs = EPOCHS\n",
    "\n",
    "best_val = 0.0\n",
    "patience_counter = 0\n",
    "PATIENCE = 6\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_loss = train_epoch(\n",
    "        model,\n",
    "        train_pad,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        teacher_forcing_ratio\n",
    "    )\n",
    "\n",
    "    val_char_acc = evaluate_char_accuracy(model, val)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}\")\n",
    "    print(f\"Train Loss: {train_loss:.4f}\")\n",
    "    print(f\"Val Char Accuracy: {val_char_acc * 100:.2f}%\")\n",
    "\n",
    "    # Early stopping logic\n",
    "    if val_char_acc > best_val:\n",
    "        best_val = val_char_acc\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"seq2seq_best.pt\")\n",
    "        print(\"New best model saved\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement ({patience_counter}/{PATIENCE})\")\n",
    "\n",
    "    if patience_counter >= PATIENCE:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "        \n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fba8eb79-65f2-454f-bf11-8b04fa3b2c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Seq2Seq model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z4/6zknnrsx3136ptsr7r6v0m3m0000gn/T/ipykernel_76986/548154539.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"seq2seq_best.pt\"))\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"seq2seq_best.pt\"))\n",
    "model.eval()\n",
    "print(\"Best Seq2Seq model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57a7f3d5-1f7c-49da-b6d4-66ec44e0c3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : Delhi\n",
      "Beam:   दिल्ली\n",
      "------------------------------\n",
      "Input : Kolkata\n",
      "Beam:   कोलकत\n",
      "------------------------------\n",
      "Input : Bangalore\n",
      "Beam:   बंगलोरो\n",
      "------------------------------\n",
      "Input : Rajasthan\n",
      "Beam:   राजस्थान\n",
      "------------------------------\n",
      "Input : Chandrakala\n",
      "Beam:   चंद्रकलाल\n",
      "------------------------------\n",
      "Input : Vishnupuram\n",
      "Beam:   विषुणपुरम\n",
      "------------------------------\n",
      "Input : Maharashta\n",
      "Beam:   मारहष्ट\n",
      "------------------------------\n",
      "Input : Kaveri\n",
      "Beam:   केवीरी\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "tests = [\n",
    "    \"Delhi\",\n",
    "    \"Kolkata\",\n",
    "    \"Bangalore\",\n",
    "    \"Rajasthan\",\n",
    "    \"Chandrakala\",\n",
    "    \"Vishnupuram\",\n",
    "    \"Maharashta\",\n",
    "    \"Kaveri\"\n",
    "]\n",
    "\n",
    "for w in tests:\n",
    "    print(\"Input :\", w)\n",
    "    print(\"Beam:  \", beam_transliterate(model, w))\n",
    "    # print(\"Greedy: \", greedy_transliterate(model,w))\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "456e877f-5376-40e8-b58d-ac038f335cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_char_accuracy(model, data):\n",
    "    model.eval()\n",
    "    scores = []\n",
    "\n",
    "    for en, hi in data:\n",
    "        pred = beam_transliterate(model, en)\n",
    "        scores.append(char_accuracy(pred, hi))\n",
    "\n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aac5cfdd-d366-4de8-bb7f-55ad38bf2ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Char Accuracy:  45.29 %\n",
      "Test Char Accuracy:  45.55 %\n"
     ]
    }
   ],
   "source": [
    "val_acc = evaluate_char_accuracy(model, val)\n",
    "test_acc = evaluate_char_accuracy(model, test)\n",
    "\n",
    "print(\"Validation Char Accuracy: \", round(val_acc * 100, 2), \"%\")\n",
    "print(\"Test Char Accuracy: \", round(test_acc * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "256ec9eb-0a58-49de-80ff-5c11dc4988de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as seq2seq_best.pt\n"
     ]
    }
   ],
   "source": [
    "torch.save({\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"en_stoi\": en_stoi,\n",
    "    \"hi_stoi\": hi_stoi,\n",
    "    \"hi_itos\": hi_itos,\n",
    "    \"PAD\": PAD,\n",
    "    \"SOS\": SOS,\n",
    "    \"EOS\": EOS,\n",
    "    \"EMBED_DIM\": EMBED_DIM,\n",
    "    \"HIDDEN_DIM\": HIDDEN_DIM\n",
    "}, \"seq2seq_best.pt\")\n",
    "\n",
    "print(\"Model saved as seq2seq_best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8708183b-d403-4dac-be3a-23a1f04e521a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (translit)",
   "language": "python",
   "name": "translit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
