{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4ce27f5-22e1-40a3-8462-26aec5cb9cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory: /Users/jasleenkaur/Desktop/translit-consistency\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_ROOT = \"/Users/jasleenkaur/Desktop/translit-consistency\"\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "print(\"Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c8ff48-aa77-4dba-bae9-152f70aa48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from g2p_en import G2p\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b83ab7f-864b-4a3d-9022-658bd06867fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e711de10-1603-442b-b1ad-b7c44618c00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_english(word):\n",
    "    return {\n",
    "        \"delhi\": \"dilli\",\n",
    "        \"bangalore\": \"bangalor\",\n",
    "        \"bengaluru\": \"bangalor\",\n",
    "        \"maharashta\": \"maharashtra\",\n",
    "    }.get(word.lower(), word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "817918e5-9d61-4d21-8ac1-904fd43e1d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(word, stoi):\n",
    "    if stoi is en_stoi:\n",
    "        word = normalize_english(word)\n",
    "    return [stoi[SOS]] + [stoi[c] for c in word] + [stoi[EOS]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa43fd85-1c6d-4b51-905c-a56325a49218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx = 0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first = True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        outputs, (h, c) = self.lstm(emb)\n",
    "        return outputs, h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "efe341ae-331c-4e47-aad1-3ae76c813ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.scale = 1.0 / (hidden_dim ** 0.5)\n",
    "\n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "        \"\"\"\n",
    "        decoder_hidden: (B, H)\n",
    "        encoder_outputs: (B, src_len, H)\n",
    "        \"\"\"\n",
    "        # (B, src_len)\n",
    "        scores = torch.bmm(\n",
    "            encoder_outputs,\n",
    "            decoder_hidden.unsqueeze(2)\n",
    "        ).squeeze(2)\n",
    "\n",
    "        attn_weights = torch.softmax(scores * self.scale, dim=1)\n",
    "\n",
    "        # (B, H)\n",
    "        context = torch.bmm(\n",
    "            attn_weights.unsqueeze(1),\n",
    "            encoder_outputs\n",
    "        ).squeeze(1)\n",
    "\n",
    "        return context, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5089cfdf-43a9-4bc7-9c87-0b31a67a7d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.attention = LuongAttention(hidden_dim)\n",
    "        self.lstm = nn.LSTM(embed_dim + hidden_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, h, c, encoder_outputs):\n",
    "        # x: (B, 1)\n",
    "        emb = self.embedding(x)  # (B, 1, E)\n",
    "\n",
    "        # Attention\n",
    "        context, _ = self.attention(h[-1], encoder_outputs)  # (B, H)\n",
    "        context = context.unsqueeze(1)  # (B, 1, H)\n",
    "\n",
    "        # LSTM\n",
    "        lstm_input = torch.cat([emb, context], dim=2)  # (B, 1, E+H)\n",
    "        output, (h, c) = self.lstm(lstm_input, (h, c))  # output: (B, 1, H)\n",
    "\n",
    "        logits = self.fc(output.squeeze(1))  # (B, vocab)\n",
    "        return logits, h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e889bb8c-098a-404d-b9ac-1608c80d1a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, pad_idx):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.pad_idx = pad_idx\n",
    "\n",
    "    def forward(self, src, tgt, teacher_forcing_ratio=0.5):\n",
    "        \"\"\"\n",
    "        src: (B, src_len)\n",
    "        tgt: (B, tgt_len)\n",
    "        \"\"\"\n",
    "        batch_size, tgt_len = tgt.shape\n",
    "        vocab_size = self.decoder.fc.out_features\n",
    "\n",
    "        outputs = torch.zeros(batch_size, tgt_len, vocab_size).to(src.device)\n",
    "\n",
    "        encoder_outputs, h, c = self.encoder(src)\n",
    "\n",
    "        input_tok = tgt[:, 0].unsqueeze(1)\n",
    "\n",
    "        for t in range(1, tgt_len):\n",
    "            logits, h, c = self.decoder(input_tok, h, c, encoder_outputs)\n",
    "            outputs[:, t] = logits\n",
    "\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = logits.argmax(1).unsqueeze(1)  \n",
    "\n",
    "            input_tok = tgt[:, t].unsqueeze(1) if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c5142cd4-679b-45e3-98b6-73557de6a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMON_FIXES = {\n",
    "    \"िि\": \"ि\",\n",
    "    \"ाा\": \"ा\",\n",
    "    \"ुु\": \"ु\",\n",
    "    \"ूू\": \"ू\",\n",
    "    \"ेे\": \"े\",\n",
    "    \"ोो\": \"ो\"\n",
    "}\n",
    "\n",
    "def normalize_hindi(text):\n",
    "    for b, g in COMMON_FIXES.items():\n",
    "        text = text.replace(b, g)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1b14cac-3c61-45d7-82ea-0bba057c869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_hindi(text):\n",
    "    # 1️⃣ Collapse duplicated matras (िि → ि, etc.)\n",
    "    for m in [\"ि\", \"ी\", \"ा\", \"ु\", \"ू\", \"े\", \"ो\"]:\n",
    "        text = text.replace(m + m, m)\n",
    "\n",
    "    # 2️⃣ Fix duplicated final consonant (ष्ट्ट → ष्ट)\n",
    "    if len(text) >= 2 and text[-1] == text[-2]:\n",
    "        text = text[:-1]\n",
    "\n",
    "    # 3️⃣ PROTECT common Hindi suffixes\n",
    "    protected_suffixes = (\n",
    "        \"स्थान\", \"पुर\", \"नगर\", \"गंज\", \"गढ़\", \"पुरम\"\n",
    "    )\n",
    "    for suf in protected_suffixes:\n",
    "        if text.endswith(suf):\n",
    "            return text   # DO NOTHING further\n",
    "\n",
    "    # 4️⃣ Trim hallucinated trailing junk ONLY if long\n",
    "    if len(text) >= 7:\n",
    "        # remove trailing vowels like \"जो\", \"यी\", \"ऊ\"\n",
    "        if text[-1] in {\"ो\", \"ू\", \"ी\"}:\n",
    "            text = text[:-1]\n",
    "\n",
    "        # remove trailing filler consonants\n",
    "        if text[-1] in {\"य\", \"र\"}:\n",
    "            text = text[:-1]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b388e1b-c058-48f8-8a40-39d92e6c90d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_common_seq2seq_errors(text):\n",
    "    # 1️⃣ Remove hallucinated trailing syllables\n",
    "    if text.endswith(\"का\") and len(text) > 5:\n",
    "        text = text[:-2]\n",
    "\n",
    "    # 2️⃣ Fix vowel echo (रीरे → री, रिरे → री)\n",
    "    text = text.replace(\"रीरे\", \"री\")\n",
    "    text = text.replace(\"रिरे\", \"री\")\n",
    "\n",
    "    # 3️⃣ Fix double syllable drift (ल्ली → ली)\n",
    "    text = text.replace(\"ल्लि\", \"ल्ली\")\n",
    "    text = text.replace(\"मिल्लि\", \"दिल्ली\")\n",
    "\n",
    "    # 4️⃣ Remove dangling halant at end\n",
    "    if text.endswith(\"्\"):\n",
    "        text = text[:-1]\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ff7c3fb9-d39c-4cf4-b096-ef4348363cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_transliterate(model, word, beam_width=3, max_len=40):\n",
    "    model.eval()\n",
    "\n",
    "    src = torch.tensor([encode(word.lower(), en_stoi)], dtype=torch.long).to(device)\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, h, c = model.encoder(src)\n",
    "\n",
    "    beams = [([hi_stoi[SOS]], 0.0, h, c)]\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        new_beams = []\n",
    "        for seq, score, h, c in beams:\n",
    "            if seq[-1] == hi_stoi[EOS]:\n",
    "                new_beams.append((seq, score, h, c))\n",
    "                continue\n",
    "\n",
    "            input_tok = torch.tensor([[seq[-1]]], device=device)\n",
    "            with torch.no_grad():\n",
    "                logits, h_new, c_new = model.decoder(input_tok, h, c, encoder_outputs)\n",
    "\n",
    "            log_probs = torch.log_softmax(logits[0], dim=-1)\n",
    "            topk = torch.topk(log_probs, beam_width)\n",
    "\n",
    "            for idx, val in zip(topk.indices, topk.values):\n",
    "                next_char = hi_itos[idx.item()]\n",
    "\n",
    "                penalty = 0.0\n",
    "                if seq.count(idx.item()) >= 2:\n",
    "                    penalty = 1.5\n",
    "                    \n",
    "                new_beams.append(\n",
    "                    (seq + [idx.item()], score + val.item() - penalty, h_new, c_new)\n",
    "                )\n",
    "\n",
    "        beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_width]\n",
    "        if all(seq[-1] == hi_stoi[EOS] for seq, _, _, _ in beams):\n",
    "            break\n",
    "\n",
    "    best = beams[0][0]\n",
    "    out = \"\".join(\n",
    "        hi_itos[i] for i in best\n",
    "        if i not in {hi_stoi[SOS], hi_stoi[EOS], hi_stoi[PAD]}\n",
    "    )\n",
    "    out = normalize_hindi(out)\n",
    "    out = postprocess_hindi(out)\n",
    "    out = fix_common_seq2seq_errors(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f69977c8-58dc-4a8f-a080-bfdc34a4bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "checkpoint = torch.load(\"seq2seq_stable.pt\", map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "73bb4b33-0a4e-4e7a-8eb2-b1e95830f67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stoi = checkpoint[\"en_stoi\"]\n",
    "hi_stoi = checkpoint[\"hi_stoi\"]\n",
    "hi_itos = checkpoint[\"hi_itos\"]\n",
    "\n",
    "PAD = checkpoint[\"PAD\"]\n",
    "SOS = checkpoint[\"SOS\"]\n",
    "EOS = checkpoint[\"EOS\"]\n",
    "\n",
    "EMBED_DIM = checkpoint[\"EMBED_DIM\"]\n",
    "HIDDEN_DIM = checkpoint[\"HIDDEN_DIM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b5b510d-6b15-439a-b7c2-c20a0b7c0b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(\n",
    "    vocab_size = len(en_stoi), \n",
    "    embed_dim = EMBED_DIM, \n",
    "    hidden_dim = HIDDEN_DIM\n",
    ").to(device)\n",
    "\n",
    "decoder = Decoder(\n",
    "    vocab_size = len(hi_stoi), \n",
    "    embed_dim = EMBED_DIM, \n",
    "    hidden_dim = HIDDEN_DIM\n",
    ").to(device)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, hi_stoi[PAD]).to(device)\n",
    "model.load_state_dict(checkpoint[\"model_state\"])\n",
    "model.eval()\n",
    "\n",
    "print(\"Seq2Seq model loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c752547a-1224-4e0b-b97b-51e4875933a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from p2g import transliterate_p2g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f2ca760-3296-4911-92bd-6f21bec577b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_accuracy(pred, gold):\n",
    "    m = min(len(pred), len(gold))\n",
    "    return sum(pred[i] == gold[i] for i in range(m)) / max(len(gold), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1c15509-6adf-4279-8378-3741c1a91dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(word, seq_out, p2g_out):\n",
    "    return [\n",
    "        len(seq_out) / max(len(word), 1),      # len_ratio\n",
    "        seq_out.count(\"्\"),                    # seq_halants\n",
    "        p2g_out.count(\"्\"),                    # p2g_halants\n",
    "        len(seq_out) - len(set(seq_out)),      # seq_repeats\n",
    "        len(p2g_out) - len(set(p2g_out)),      # p2g_repeats\n",
    "        int(seq_out[-1] in \"ािीुूेो\") if seq_out else 0,\n",
    "        int(p2g_out[-1] in \"ािीुूेो\") if p2g_out else 0,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "790d0166-f81b-49c1-aeac-082205e42d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ed79ad0-8bf1-4740-a70c-717696f88392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 32835\n",
      "Val: 4104\n",
      "Test: 4105\n"
     ]
    }
   ],
   "source": [
    "import json, random\n",
    "\n",
    "with open(\"data/processed/aligned_pairs_high_conf.json\", encoding = \"utf-8\") as f:\n",
    "    raw_pairs = json.load(f)\n",
    "\n",
    "pairs = [(en.lower(), hi) for en, hi, _ in raw_pairs]\n",
    "random.seed(42)\n",
    "random.shuffle(pairs)\n",
    "\n",
    "n = len(pairs)\n",
    "train = pairs[:int(0.8 * n)]\n",
    "val   = pairs[int(0.8 * n):int(0.9 * n)]\n",
    "test  = pairs[int(0.9 * n):]\n",
    "\n",
    "print(\"Train:\", len(train))\n",
    "print(\"Val:\", len(val))\n",
    "print(\"Test:\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "60079ca4-f89b-41ec-a98d-35e968916700",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for en, hi in train[:5000]:   # start with 5k only\n",
    "    seq_out = beam_transliterate(model, en)\n",
    "    p2g_out = transliterate_p2g(en)\n",
    "\n",
    "    features = extract_features(en, seq_out, p2g_out)\n",
    "    X.append(features)\n",
    "\n",
    "    # Label: which output is better?\n",
    "    seq_acc = char_accuracy(seq_out, hi)\n",
    "    p2g_acc = char_accuracy(p2g_out, hi)\n",
    "\n",
    "    label = 1 if seq_acc >= p2g_acc else 0\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "73b51700-e600-47ae-9fae-2bf50492bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a318e689-3301-4ac0-9b6b-65983c575fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier trained\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(\n",
    "    n_estimators = 200,\n",
    "    max_depth = 10,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "clf.fit(X, y)\n",
    "print(\"Classifier trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d42eed87-73c9-48da-afbb-033611ac0a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_transliterate(word):\n",
    "    seq_out = beam_transliterate(model, word)\n",
    "    p2g_out = transliterate_p2g(word)\n",
    "\n",
    "    features = extract_features(word, seq_out, p2g_out)\n",
    "    decision = clf.predict([features])[0]\n",
    "\n",
    "    return seq_out if decision == 1 else p2g_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d3be245c-ab50-483c-9999-84dce951fdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_system(data, predict_fn, limit=None):\n",
    "    scores = []\n",
    "\n",
    "    for i, (en, hi) in enumerate(data):\n",
    "        if limit and i >= limit:\n",
    "            break\n",
    "\n",
    "        pred = predict_fn(en)\n",
    "        scores.append(char_accuracy(pred, hi))\n",
    "\n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "05946030-ad9e-4987-a87c-59cfb68d4b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq Val: 47.79 %\n",
      "P2G Val: 34.76 %\n",
      "Hybrid (heuristic) Val: 47.83 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Seq2Seq Val:\",\n",
    "      round(evaluate_system(val, lambda w: beam_transliterate(model, w), 2000) * 100, 2), \"%\")\n",
    "\n",
    "print(\"P2G Val:\",\n",
    "      round(evaluate_system(val, transliterate_p2g, 2000) * 100, 2), \"%\")\n",
    "\n",
    "print(\"Hybrid (heuristic) Val:\",\n",
    "      round(evaluate_system(val, hybrid_transliterate, 2000) * 100, 2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8d27fff0-a9f3-4d0a-9f2d-aea0ee787e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_type(pred, gold):\n",
    "    if len(pred) < len(gold):\n",
    "        return \"UNDER\"\n",
    "    if len(pred) > len(gold):\n",
    "        return \"OVER\"\n",
    "    if \"्\" in pred and \"्\" not in gold:\n",
    "        return \"HALANT\"\n",
    "    return \"OTHER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aa6e12bb-cf7d-44ef-9122-4bee3caea1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def analyze_errors_seq(data, limit=1000):\n",
    "    counter = Counter()\n",
    "\n",
    "    for i, (en, hi) in enumerate(data):\n",
    "        if i >= limit:\n",
    "            break\n",
    "\n",
    "        pred = beam_transliterate(model, en)\n",
    "        counter[error_type(pred, hi)] += 1\n",
    "\n",
    "    total = sum(counter.values())\n",
    "    return {k: round(v / total * 100, 2) for k, v in counter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fa1e4156-655b-4b8b-94f4-8b3c08e001e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_errors_hybrid(data, limit=1000):\n",
    "    counter = Counter()\n",
    "\n",
    "    for i, (en, hi) in enumerate(data):\n",
    "        if i >= limit:\n",
    "            break\n",
    "\n",
    "        pred = hybrid_transliterate(en)\n",
    "        counter[error_type(pred, hi)] += 1\n",
    "    total = sum(counter.values())\n",
    "    return {k: round(v / total * 100, 2) for k, v in counter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ef4ac77d-f56b-4698-be7e-c6e22c5fe22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2Seq Errors: {'OTHER': 37.0, 'UNDER': 27.4, 'OVER': 34.7, 'HALANT': 0.9}\n",
      "Hybrid Errors: {'OTHER': 37.0, 'UNDER': 27.5, 'OVER': 34.6, 'HALANT': 0.9}\n"
     ]
    }
   ],
   "source": [
    "print(\"Seq2Seq Errors:\", analyze_errors_seq(val))\n",
    "print(\"Hybrid Errors:\", analyze_errors_hybrid(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06e1357-d61f-44fc-87f7-20b502f75c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "decisions = Counter()\n",
    "\n",
    "for en, hi in val[:2000]:\n",
    "    seq_out = beam_transliterate(model, en)\n",
    "    p2g_out = transliterate_p2g(en)\n",
    "\n",
    "    feats = extract_features(en, seq_out, p2g_out)\n",
    "    decision = clf.predict([feats])[0]\n",
    "\n",
    "    decisions[\"SEQ2SEQ\" if decision == 1 else \"P2G\"] += 1\n",
    "\n",
    "print(decisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceba8670-05cd-4d29-aec8-9d0ec1141671",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "torch.save(checkpoint, \"seq2seq_final.pt\")\n",
    "joblib.dump(clf, \"confidence_selector.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (translit)",
   "language": "python",
   "name": "translit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
