{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45456b09-a96e-4705-a12e-eb7defe3510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f55959d-62af-47e4-8408-e34c49b84ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/raw/parallel-n/IITB.en-hi.en'),\n",
       " PosixPath('data/raw/parallel-n/IITB.en-hi.hi')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = Path(\"data/raw/parallel-n\")\n",
    "files = list(data_path.glob(\"*\"))[:5]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dab0c20-3bbf-4bdf-bef3-c4e5a28ae42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. EN: Give your application an accessibility workout\n",
      "   HI: अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें\n",
      "--------------------------------------------------\n",
      "2. EN: Accerciser Accessibility Explorer\n",
      "   HI: एक्सेर्साइसर पहुंचनीयता अन्वेषक\n",
      "--------------------------------------------------\n",
      "3. EN: The default plugin layout for the bottom panel\n",
      "   HI: निचले पटल के लिए डिफोल्ट प्लग-इन खाका\n",
      "--------------------------------------------------\n",
      "4. EN: The default plugin layout for the top panel\n",
      "   HI: ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका\n",
      "--------------------------------------------------\n",
      "5. EN: A list of plugins that are disabled by default\n",
      "   HI: उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से निष्क्रिय किया गया है\n",
      "--------------------------------------------------\n",
      "6. EN: Highlight duration\n",
      "   HI: अवधि को हाइलाइट रकें\n",
      "--------------------------------------------------\n",
      "7. EN: The duration of the highlight box when selecting accessible nodes\n",
      "   HI: पहुंचनीय आसंधि (नोड) को चुनते समय हाइलाइट बक्से की अवधि\n",
      "--------------------------------------------------\n",
      "8. EN: Highlight border color\n",
      "   HI: सीमांत (बोर्डर) के रंग को हाइलाइट करें\n",
      "--------------------------------------------------\n",
      "9. EN: The color and opacity of the highlight border.\n",
      "   HI: हाइलाइट किए गए सीमांत का रंग और अपारदर्शिता।\n",
      "--------------------------------------------------\n",
      "10. EN: Highlight fill color\n",
      "   HI: भराई के रंग को हाइलाइट करें\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "en_file = \"data/raw/parallel-n/IITB.en-hi.en\"\n",
    "hi_file = \"data/raw/parallel-n/IITB.en-hi.hi\"\n",
    "\n",
    "with open(en_file, encoding = \"utf-8\") as f_en, open(hi_file, encoding = \"utf-8\") as f_hi:\n",
    "    for i in range(10):\n",
    "        en_line = f_en.readline().strip()\n",
    "        hi_line = f_hi.readline().strip()\n",
    "        print(f\"{i+1}. EN: {en_line}\")\n",
    "        print(f\"   HI: {hi_line}\")\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b55380d-df87-43e1-a4ba-d93b2db2bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c037a729-510a-4c51-9514-b0bfb4001442",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NER ALONE DIDN'T WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a1597a4-303c-4a76-b412-7bbc98839694",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "sentence = \"Accerciser Accessibility Explorer\"\n",
    "doc = nlp(sentence)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fdc4b54-8e39-4007-8636-7af5815f05df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMBINING NER AND HEURISTICS (HYBRID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4858bb5-d14a-4574-9d4c-31d85af40b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10000 sentences...\n",
      "Done\n",
      "Total extracted names:  1227\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Incremental',\n",
       " 'Programs',\n",
       " 'Hyperlink',\n",
       " 'The New BSD License See the COPYING and',\n",
       " 'Elevator',\n",
       " 'Details:%',\n",
       " 'Law',\n",
       " 'Addrcheck',\n",
       " 'Due',\n",
       " 'Macro',\n",
       " 'Tools',\n",
       " 'Library',\n",
       " 'User',\n",
       " 'Jamestown',\n",
       " 'Skip',\n",
       " 'Asked',\n",
       " 'New View',\n",
       " 'Mine',\n",
       " 'Specify',\n",
       " 'Athena']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load English NLP pipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable = [\"parser\", \"tagger\", \"lemmatizer\"])\n",
    "\n",
    "en_file = Path(\"data/raw/parallel-n/IITB.en-hi.en\")\n",
    "\n",
    "extracted_names = set()\n",
    "\n",
    "MAX_LINES = 10000\n",
    "\n",
    "with open(en_file, encoding=\"utf-8\") as f:\n",
    "    lines = []\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= MAX_LINES:\n",
    "            break\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            lines.append(line)\n",
    "\n",
    "print(f\"Processing {len(lines)} sentences...\")\n",
    "\n",
    "# Process in batches\n",
    "for doc in nlp.pipe(lines, batch_size = 500):\n",
    "    # Part 1: NER\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in {\"PERSON\", \"ORG\", \"PRODUCT\", \"GPE\"}:\n",
    "            extracted_names.add(ent.text)\n",
    "\n",
    "    # Part 2: Heuristics\n",
    "    for token in doc:\n",
    "        if(\n",
    "            token.text[0].isupper() and\n",
    "            token.is_alpha and\n",
    "            len(token.text) > 2\n",
    "        ):\n",
    "            extracted_names.add(token.text)\n",
    "\n",
    "print(\"Done\")\n",
    "print(\"Total extracted names: \", len(extracted_names))\n",
    "list(extracted_names)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d7e3770-c4b0-46b1-bfbf-6705276798d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/processed/extracted_names_en_10k.json\", \"w\", encoding = \"utf-8\") as f:\n",
    "    json.dump(sorted(extracted_names), f, ensure_ascii = False, indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc99e4d8-5ca0-490f-b3dc-21b136cb0133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from indic_transliteration import sanscript\n",
    "from indic_transliteration.sanscript import transliterate\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0559a6-c431-401b-867a-a789d7a65c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# BASELINE ALIGNMENT PIPELINE (DISABLED – NOT USED IN RESULTS)\n",
    "# ==========================================================\n",
    "# nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"tagger\", \"lemmatizer\"])\n",
    "# ...\n",
    "# json.dump(aligned_pairs, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "397ac2f6-96fa-41a0-b264-2cb1454ff791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Highlight', 'हाइलाइट', 0.5882352941176471)\n",
      "('Highlight', 'हाइलाइट', 0.5882352941176471)\n",
      "('Highlight', 'हाइलाइट', 0.5882352941176471)\n",
      "('API', 'एपीआई', 0.5)\n",
      "('Hide', 'छिपाएं', 0.5454545454545454)\n",
      "('Console', 'कन्सोल', 0.5714285714285714)\n",
      "('IPython', 'आईपाइथन', 0.5882352941176471)\n",
      "('Monitor', 'मानिटर', 0.6666666666666666)\n",
      "('Monitor', 'मानिटर', 0.6666666666666666)\n",
      "('Highlight', 'हाइलाइट', 0.5882352941176471)\n",
      "('WIDGET', 'विडजेट', 0.5714285714285714)\n",
      "('Alpha', 'अल्फा', 1.0)\n",
      "('Des', 'डेस्कटोप', 0.5)\n",
      "('Position', 'स्थिति', 0.5714285714285714)\n",
      "('Offset', 'ओफसेट', 0.5714285714285714)\n",
      "('Name', 'नाम', 0.75)\n",
      "('URI', 'यूआरआई', 0.6)\n",
      "('Plugin', 'प्लग-इन', 0.6666666666666666)\n",
      "('Native', 'वतनी', 0.5)\n",
      "('LDTP', 'एलडीटीपी', 0.6153846153846154)\n"
     ]
    }
   ],
   "source": [
    "# nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"tagger\", \"lemmatizer\"])\n",
    "\n",
    "# def romanize_hi(word):\n",
    "#     return transliterate(word, sanscript.DEVANAGARI, sanscript.ITRANS)\n",
    "\n",
    "# def similarity(a,b):\n",
    "#     return SequenceMatcher(None, a.lower(), b.lower()).ratio()\n",
    "\n",
    "# en_file = Path(\"data/raw/parallel-n/IITB.en-hi.en\")\n",
    "# hi_file = Path(\"data/raw/parallel-n/IITB.en-hi.hi\")\n",
    "\n",
    "# MAX_LINES = 10000\n",
    "\n",
    "# en_lines, hi_lines = [], []\n",
    "\n",
    "# with open(en_file, encoding = \"utf-8\") as f_en , open(hi_file, encoding = \"utf-8\") as f_hi:\n",
    "#     for i, (en, hi) in enumerate(zip(f_en, f_hi)):\n",
    "#         if i >= MAX_LINES:\n",
    "#             break\n",
    "#         en_lines.append(en.strip())\n",
    "#         hi_lines.append(hi.strip())\n",
    "\n",
    "# aligned_pairs = []\n",
    "\n",
    "# for en_sent, hi_sent in zip(en_lines, hi_lines):\n",
    "#     doc = nlp(en_sent)\n",
    "\n",
    "#     en_names = set()\n",
    "\n",
    "#     for ent in doc.ents:\n",
    "#         if ent.label_ in {\"PERSON\", \"ORG\", \"PRODUCT\", \"GPE\"}:\n",
    "#             en_names.add(ent.text)\n",
    "\n",
    "#     for token in doc:\n",
    "#         if token.text[0].isupper() and token.is_alpha and len(token.text) > 2:\n",
    "#             en_names.add(token.text)\n",
    "\n",
    "#     if not en_names:\n",
    "#         continue\n",
    "\n",
    "#     hi_tokens = hi_sent.split()\n",
    "\n",
    "#     for en_name in en_names:\n",
    "#         best_match = None\n",
    "#         best_score = 0.0\n",
    "\n",
    "#         for hi_word in hi_tokens:\n",
    "#             if len(hi_word) < 2:\n",
    "#                 continue\n",
    "\n",
    "#             hi_roman = romanize_hi(hi_word)\n",
    "#             score = similarity(en_name, hi_roman)\n",
    "\n",
    "#             if score > best_score:\n",
    "#                 best_score = score\n",
    "#                 best_match = hi_word\n",
    "\n",
    "#         if best_score >= 0.45:\n",
    "#             aligned_pairs.append((en_name, best_match, best_score))\n",
    "\n",
    "# for pair in aligned_pairs[:20]:\n",
    "#     print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8e000676-520c-46a1-a3da-7666eac1b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open(\"data/processed/aligned_pairs_10k.json\", \"w\", encoding = \"utf-8\") as f:\n",
    "#     json.dump(aligned_pairs, f, ensure_ascii = False, indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f845bbbf-0c51-4d04-95a6-7a9232830b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data/processed/aligned_pairs_10k.json\", encoding = \"utf-8\") as f:\n",
    "    aligned_pairs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b07f0a19-fa91-4d14-b927-7884cb1508a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped = {}\n",
    "\n",
    "for en, hi, score in aligned_pairs:\n",
    "    key = (en.lower(), hi)\n",
    "\n",
    "    if key not in deduped or score > deduped[key][2]:\n",
    "        deduped[key] = (en, hi, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57d45c2a-6340-45b9-b21a-0eb772b13cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_pairs = list(deduped.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3df67eb-f671-425b-ade3-c5d11d56ce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMON_ENGLISH = {\n",
    "    \"the\", \"this\", \"that\", \"these\", \"those\", \n",
    "    \"data\", \"report\", \"give\", \"allow\", \"show\", \"hide\", \n",
    "    \"name\", \"position\", \"default\", \"settings\", \"file\", \n",
    "    \"view\", \"edit\", \"help\", \"use\", \"using\", \"used\", \n",
    "    \"set\", \"get\", \"add\", \"remove\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7d78a76-cd2f-4fb0-8658-ff90a0d7570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMON_HINDI = {\n",
    "    \"से\", \"में\", \"का\", \"की\", \"के\", \"को\", \"पर\",\n",
    "    \"है\", \"था\", \"थी\", \"थे\", \"असमर्थ\", \"संग्रहित\",\n",
    "    \"लिए\", \"द्वारा\", \"साथ\", \"बिना\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4a39cbe-8fba-4807-960e-96396e3e8882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:  3581\n",
      "After dedup:  667\n",
      "After filtering:  631\n",
      "('Highlight', 'हाइलाइट', 0.5882352941176471)\n",
      "('API', 'एपीआई', 0.5)\n",
      "('Console', 'कन्सोल', 0.5714285714285714)\n",
      "('IPython', 'आईपाइथन', 0.5882352941176471)\n",
      "('Monitor', 'मानिटर', 0.6666666666666666)\n",
      "('WIDGET', 'विडजेट', 0.5714285714285714)\n",
      "('Alpha', 'अल्फा', 1.0)\n",
      "('Des', 'डेस्कटोप', 0.5)\n",
      "('Offset', 'ओफसेट', 0.5714285714285714)\n",
      "('URI', 'यूआरआई', 0.6)\n",
      "('Plugin', 'प्लग-इन', 0.6666666666666666)\n",
      "('Native', 'वतनी', 0.5)\n",
      "('LDTP', 'एलडीटीपी', 0.6153846153846154)\n",
      "('Recorder', 'रेकोर्डर', 0.7058823529411765)\n",
      "('Creates', 'करता', 0.46153846153846156)\n",
      "('num1', '(num1)', 0.8)\n",
      "('Accerciser', 'इसे', 0.46153846153846156)\n",
      "('Changes', 'आएंगे।', 0.46153846153846156)\n",
      "('Node', '(नोड)', 0.6)\n",
      "('Alt', 'आल्ट', 0.8571428571428571)\n"
     ]
    }
   ],
   "source": [
    "filtered_pairs = []\n",
    "\n",
    "for en, hi, score in deduped_pairs:\n",
    "    if en.lower() in COMMON_ENGLISH:\n",
    "        continue\n",
    "    filtered_pairs.append((en, hi, score))\n",
    "\n",
    "print(\"Before: \", len(aligned_pairs))\n",
    "print(\"After dedup: \", len(deduped_pairs))\n",
    "print(\"After filtering: \", len(filtered_pairs))\n",
    "\n",
    "for pair in filtered_pairs[:20]:\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f37f8c7-0694-4f9f-9b75-0f2d6b4be225",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/processed/aligned_pairs_10k_clean.json\", \"w\", encoding = \"utf-8\") as f:\n",
    "    json.dump(filtered_pairs, f, ensure_ascii = False, indent = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61d6631-6789-4189-b12f-1f798a186080",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALIGNMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25301d93-03bd-4716-be28-bdf73917cfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting full dataset alignment (streaming mode)...\n",
      "Aligned pairs so far: 500\n",
      "Sentences Processed:  100000\n",
      "Aligned pairs so far: 1000\n",
      "Aligned pairs so far: 1500\n",
      "Aligned pairs so far: 2000\n",
      "Aligned pairs so far: 2501\n",
      "Aligned pairs so far: 3000\n",
      "Aligned pairs so far: 3500\n",
      "Aligned pairs so far: 4000\n",
      "Aligned pairs so far: 4500\n",
      "Aligned pairs so far: 5000\n",
      "Aligned pairs so far: 5500\n",
      "Aligned pairs so far: 6000\n",
      "Aligned pairs so far: 6500\n",
      "Aligned pairs so far: 7000\n",
      "Aligned pairs so far: 7500\n",
      "Aligned pairs so far: 8000\n",
      "Sentences Processed:  200000\n",
      "Aligned pairs so far: 8501\n",
      "Aligned pairs so far: 9000\n",
      "Aligned pairs so far: 9500\n",
      "Aligned pairs so far: 10000\n",
      "Aligned pairs so far: 10500\n",
      "Aligned pairs so far: 11000\n",
      "Aligned pairs so far: 11500\n",
      "Sentences Processed:  300000\n",
      "Aligned pairs so far: 12000\n",
      "Aligned pairs so far: 12500\n",
      "Sentences Processed:  400000\n",
      "Aligned pairs so far: 13000\n",
      "Aligned pairs so far: 13503\n",
      "Aligned pairs so far: 14007\n",
      "Aligned pairs so far: 14501\n",
      "Aligned pairs so far: 15000\n",
      "Aligned pairs so far: 15500\n",
      "Aligned pairs so far: 16003\n",
      "Aligned pairs so far: 16500\n",
      "Aligned pairs so far: 17000\n",
      "Aligned pairs so far: 17500\n",
      "Aligned pairs so far: 18000\n",
      "Aligned pairs so far: 18500\n",
      "Aligned pairs so far: 19000\n",
      "Aligned pairs so far: 19500\n",
      "Aligned pairs so far: 20002\n",
      "Aligned pairs so far: 20500\n",
      "Aligned pairs so far: 21000\n",
      "Aligned pairs so far: 21500\n",
      "Aligned pairs so far: 22000\n",
      "Aligned pairs so far: 22500\n",
      "Aligned pairs so far: 23000\n",
      "Aligned pairs so far: 23500\n",
      "Aligned pairs so far: 24000\n",
      "Aligned pairs so far: 24500\n",
      "Aligned pairs so far: 25001\n",
      "Aligned pairs so far: 25500\n",
      "Aligned pairs so far: 26000\n",
      "Aligned pairs so far: 26500\n",
      "Aligned pairs so far: 27000\n",
      "Sentences Processed:  500000\n",
      "Aligned pairs so far: 27501\n",
      "Aligned pairs so far: 28000\n",
      "Aligned pairs so far: 28500\n",
      "Aligned pairs so far: 29000\n",
      "Aligned pairs so far: 29501\n",
      "Aligned pairs so far: 30000\n",
      "Aligned pairs so far: 30500\n",
      "Aligned pairs so far: 31000\n",
      "Aligned pairs so far: 31500\n",
      "Aligned pairs so far: 32000\n",
      "Aligned pairs so far: 32500\n",
      "Aligned pairs so far: 33000\n",
      "Aligned pairs so far: 33500\n",
      "Aligned pairs so far: 34000\n",
      "Aligned pairs so far: 34500\n",
      "Aligned pairs so far: 35000\n",
      "Aligned pairs so far: 35500\n",
      "Aligned pairs so far: 36002\n",
      "Aligned pairs so far: 36500\n",
      "Aligned pairs so far: 37001\n",
      "Aligned pairs so far: 37502\n",
      "Aligned pairs so far: 38000\n",
      "Aligned pairs so far: 38500\n",
      "Aligned pairs so far: 39000\n",
      "Aligned pairs so far: 39503\n",
      "Aligned pairs so far: 40000\n",
      "Aligned pairs so far: 40500\n",
      "Aligned pairs so far: 41000\n",
      "Aligned pairs so far: 41500\n",
      "Sentences Processed:  600000\n",
      "Aligned pairs so far: 42000\n",
      "Aligned pairs so far: 42500\n",
      "Aligned pairs so far: 43000\n",
      "Aligned pairs so far: 43500\n",
      "Aligned pairs so far: 44000\n",
      "Aligned pairs so far: 44500\n",
      "Aligned pairs so far: 45000\n",
      "Aligned pairs so far: 45500\n",
      "Aligned pairs so far: 46000\n",
      "Aligned pairs so far: 46500\n",
      "Aligned pairs so far: 47000\n",
      "Aligned pairs so far: 47501\n",
      "Aligned pairs so far: 48000\n",
      "Aligned pairs so far: 48500\n",
      "Aligned pairs so far: 49000\n",
      "Aligned pairs so far: 49500\n",
      "Aligned pairs so far: 50000\n",
      "Aligned pairs so far: 50500\n",
      "Aligned pairs so far: 51001\n",
      "Sentences Processed:  700000\n",
      "Aligned pairs so far: 51500\n",
      "Aligned pairs so far: 52001\n",
      "Aligned pairs so far: 52500\n",
      "Sentences Processed:  800000\n",
      "Aligned pairs so far: 53000\n",
      "Aligned pairs so far: 53500\n",
      "Aligned pairs so far: 54000\n",
      "Aligned pairs so far: 54500\n",
      "Sentences Processed:  900000\n",
      "Aligned pairs so far: 55000\n",
      "Aligned pairs so far: 55500\n",
      "Aligned pairs so far: 56000\n",
      "Aligned pairs so far: 56500\n",
      "Aligned pairs so far: 57000\n",
      "Aligned pairs so far: 57500\n",
      "Sentences Processed:  1000000\n",
      "Aligned pairs so far: 58000\n",
      "Aligned pairs so far: 58500\n",
      "Aligned pairs so far: 59001\n",
      "Sentences Processed:  1100000\n",
      "Aligned pairs so far: 59502\n",
      "Aligned pairs so far: 60000\n",
      "Aligned pairs so far: 60502\n",
      "Aligned pairs so far: 61000\n",
      "Aligned pairs so far: 61500\n",
      "Aligned pairs so far: 62001\n",
      "Aligned pairs so far: 62502\n",
      "Aligned pairs so far: 63000\n",
      "Aligned pairs so far: 63500\n",
      "Aligned pairs so far: 64001\n",
      "Aligned pairs so far: 64500\n",
      "Aligned pairs so far: 65001\n",
      "Aligned pairs so far: 65500\n",
      "Aligned pairs so far: 66000\n",
      "Aligned pairs so far: 66501\n",
      "Aligned pairs so far: 67002\n",
      "Aligned pairs so far: 67500\n",
      "Aligned pairs so far: 68000\n",
      "Sentences Processed:  1200000\n",
      "Aligned pairs so far: 68500\n",
      "Aligned pairs so far: 69002\n",
      "Aligned pairs so far: 69500\n",
      "Aligned pairs so far: 70009\n",
      "Aligned pairs so far: 70501\n",
      "Aligned pairs so far: 71001\n",
      "Aligned pairs so far: 71500\n",
      "Aligned pairs so far: 72000\n",
      "Aligned pairs so far: 72500\n",
      "Aligned pairs so far: 73002\n",
      "Aligned pairs so far: 73501\n",
      "Aligned pairs so far: 74008\n",
      "Aligned pairs so far: 74501\n",
      "Aligned pairs so far: 75000\n",
      "Aligned pairs so far: 75500\n",
      "Aligned pairs so far: 76000\n",
      "Aligned pairs so far: 76500\n",
      "Sentences Processed:  1300000\n",
      "Aligned pairs so far: 77003\n",
      "Aligned pairs so far: 77501\n",
      "Aligned pairs so far: 78000\n",
      "Aligned pairs so far: 78501\n",
      "Aligned pairs so far: 79000\n",
      "Aligned pairs so far: 79500\n",
      "Aligned pairs so far: 80000\n",
      "Aligned pairs so far: 80500\n",
      "Aligned pairs so far: 81001\n",
      "Aligned pairs so far: 81500\n",
      "Aligned pairs so far: 82000\n",
      "Aligned pairs so far: 82501\n",
      "Aligned pairs so far: 83002\n",
      "Aligned pairs so far: 83500\n",
      "Aligned pairs so far: 84000\n",
      "Aligned pairs so far: 84500\n",
      "Aligned pairs so far: 85000\n",
      "Aligned pairs so far: 85500\n",
      "Aligned pairs so far: 86002\n",
      "Aligned pairs so far: 86500\n",
      "Aligned pairs so far: 87003\n",
      "Aligned pairs so far: 87500\n",
      "Aligned pairs so far: 88000\n",
      "Aligned pairs so far: 88501\n",
      "Aligned pairs so far: 89000\n",
      "Aligned pairs so far: 89500\n",
      "Aligned pairs so far: 90001\n",
      "Aligned pairs so far: 90502\n",
      "Aligned pairs so far: 91000\n",
      "Aligned pairs so far: 91500\n",
      "Aligned pairs so far: 92000\n",
      "Aligned pairs so far: 92500\n",
      "Aligned pairs so far: 93001\n",
      "Aligned pairs so far: 93500\n",
      "Aligned pairs so far: 94001\n",
      "Sentences Processed:  1400000\n",
      "Aligned pairs so far: 94500\n",
      "Aligned pairs so far: 95001\n",
      "Aligned pairs so far: 95510\n",
      "Aligned pairs so far: 96000\n",
      "Aligned pairs so far: 96500\n",
      "Aligned pairs so far: 97000\n",
      "Aligned pairs so far: 97502\n",
      "Aligned pairs so far: 98000\n",
      "Aligned pairs so far: 98500\n",
      "Aligned pairs so far: 99000\n",
      "Aligned pairs so far: 99501\n",
      "Aligned pairs so far: 100002\n",
      "Aligned pairs so far: 100500\n",
      "Aligned pairs so far: 101001\n",
      "Aligned pairs so far: 101500\n",
      "Aligned pairs so far: 102000\n",
      "Aligned pairs so far: 102500\n",
      "Aligned pairs so far: 103000\n",
      "Aligned pairs so far: 103500\n",
      "Aligned pairs so far: 104004\n",
      "Aligned pairs so far: 104500\n",
      "Aligned pairs so far: 105125\n",
      "Aligned pairs so far: 105502\n",
      "Sentences Processed:  1500000\n",
      "Aligned pairs so far: 106007\n",
      "Aligned pairs so far: 106501\n",
      "Aligned pairs so far: 107000\n",
      "Aligned pairs so far: 107500\n",
      "Aligned pairs so far: 108000\n",
      "Aligned pairs so far: 108502\n",
      "Aligned pairs so far: 109000\n",
      "Aligned pairs so far: 109500\n",
      "Aligned pairs so far: 110000\n",
      "Aligned pairs so far: 110502\n",
      "Aligned pairs so far: 111000\n",
      "Aligned pairs so far: 111500\n",
      "Aligned pairs so far: 112000\n",
      "Aligned pairs so far: 112503\n",
      "Aligned pairs so far: 113000\n",
      "Aligned pairs so far: 113503\n",
      "Sentences Processed:  1600000\n",
      "Aligned pairs so far: 114000\n",
      "Aligned pairs so far: 114503\n",
      "Aligned pairs so far: 115000\n",
      "Aligned pairs so far: 115501\n",
      "Aligned pairs so far: 116000\n",
      "Aligned pairs so far: 116500\n",
      "Aligned pairs so far: 117000\n",
      "Aligned pairs so far: 117502\n",
      "Aligned pairs so far: 118005\n",
      "Aligned pairs so far: 118502\n",
      "Aligned pairs so far: 119009\n",
      "Aligned pairs so far: 119500\n",
      "Aligned pairs so far: 120000\n",
      "Aligned pairs so far: 120500\n",
      "Aligned pairs so far: 121000\n",
      "Aligned pairs so far: 121500\n",
      "Aligned pairs so far: 122000\n",
      "Total aligned pairs:  122092\n",
      "Full dataset alignment completed\n",
      "Total aligned pairs:  122092\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "SIM_THRESHOLD = 0.5\n",
    "\n",
    "COMMON_ENGLISH = {\n",
    "    \"the\", \"this\", \"that\", \"these\", \"those\", \n",
    "    \"data\", \"report\", \"give\", \"allow\", \"show\", \"hide\", \n",
    "    \"name\", \"position\", \"default\", \"settings\", \"file\", \n",
    "    \"view\", \"edit\", \"help\", \"use\", \"using\", \"used\", \n",
    "    \"set\", \"get\", \"add\", \"remove\"\n",
    "}\n",
    "\n",
    "SEMANTIC_IDENTIFIER_WORDS = {\n",
    "    \"name\", \"display\", \"value\", \"default\", \"file\",\n",
    "    \"user\", \"setting\", \"config\", \"option\", \"property\",\n",
    "    \"area\", \"reset\", \"mode\", \"type\", \"level\", \"status\"\n",
    "}\n",
    "\n",
    "COMMON_HINDI = {\n",
    "    \"से\", \"में\", \"का\", \"की\", \"के\", \"को\", \"पर\",\n",
    "    \"है\", \"था\", \"थी\", \"थे\", \"असमर्थ\", \"संग्रहित\",\n",
    "    \"लिए\", \"द्वारा\", \"साथ\", \"बिना\"\n",
    "}\n",
    "\n",
    "DEMONYM_TRANSLATIONS = {\n",
    "    \"अमेरिकी\", \"ब्रिटिश\", \"भारतीय\", \"चीनी\", \"जापानी\"\n",
    "}\n",
    "\n",
    "BAD_ENGLISH = {\n",
    "    \"american\", \"british\", \"baltic\", \"hungarian\",\n",
    "    \"european\", \"african\", \"asian\", \"arab\"\n",
    "}\n",
    "\n",
    "ENGLISH_DEMONYMS = {\n",
    "    \"america\", \"american\", \"turkish\", \"british\", \"french\",\n",
    "    \"german\", \"italian\", \"spanish\", \"chinese\", \"japanese\",\n",
    "    \"indian\", \"european\", \"african\", \"asian\"\n",
    "}\n",
    "\n",
    "DIRECTIONAL_ADJECTIVES = {\n",
    "    \"western\", \"eastern\", \"northern\", \"southern\",\n",
    "    \"central\", \"global\", \"local\"\n",
    "}\n",
    "    \n",
    "nlp = spacy.load(\"en_core_web_sm\", disable = [\"parser\", \"lemmatizer\"])\n",
    "\n",
    "def is_title_like(doc):\n",
    "    \"\"\"\n",
    "    Heuristic: sentence is title-like if it has no verb\n",
    "    \"\"\"\n",
    "    return not any(token.pos_ == \"VERB\" for token in doc)\n",
    "\n",
    "def is_devanagari(word):\n",
    "    \"\"\"\n",
    "    Returns true if all characters in the word are Devanagari\n",
    "    \"\"\"\n",
    "    return all('\\u0900' <= ch <= '\\u097F' for ch in word)\n",
    "\n",
    "def normalize_hindi(word):\n",
    "    # Keep only Devanagari characters\n",
    "    word = re.sub(r\"[^\\u0900-\\u097F]\", \"\", word)\n",
    "\n",
    "    # Always remove trailing visarga\n",
    "    word = word.rstrip(\"ः\")\n",
    "\n",
    "    return word\n",
    "\n",
    "def is_plural_english(word):\n",
    "    return word.lower().endswith(\"s\") and len(word) > 4\n",
    "\n",
    "def split_camel_case(word):\n",
    "    return re.findall(r\"[A-Z][a-z]*\", word)\n",
    "\n",
    "def is_bad_short_english(word):\n",
    "    return len(word) <= 2\n",
    "\n",
    "def is_acronym(word):\n",
    "    return word.isupper() and len(word) >= 3\n",
    "\n",
    "def looks_like_translation(en, hi):\n",
    "    \"\"\"\n",
    "    Returns true if hindi word is likely a semantic translation\n",
    "    rather than a phonetic transliteration.\n",
    "    \"\"\"\n",
    "    hi_roman = romanize_hi(hi)\n",
    "    if len(hi_roman) <= 3 and len(en) >= 4:\n",
    "        return True\n",
    "    if abs(len(en) - len(hi_roman)) > 4:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_native_hindi_translation(hi_word):\n",
    "    \"\"\"\n",
    "    Detects short native Hindi words likely to be translations\n",
    "    rather than transliterations.\n",
    "    \"\"\"\n",
    "    return len(hi_word) <= 3\n",
    "    \n",
    "def romanize_hi(word):\n",
    "    try:\n",
    "        return transliterate(word, sanscript.DEVANAGARI, sanscript.ITRANS)\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def similarity(a,b):\n",
    "    return SequenceMatcher(None, a.lower(), b.lower()).ratio()\n",
    "\n",
    "en_file = Path(\"data/raw/parallel-n/IITB.en-hi.en\")\n",
    "hi_file = Path(\"data/raw/parallel-n/IITB.en-hi.hi\")\n",
    "\n",
    "print(\"Starting full dataset alignment (streaming mode)...\")\n",
    "\n",
    "aligned_pairs = set()\n",
    "last_logged = 0\n",
    "total_sentences = 0\n",
    "\n",
    "with open(en_file, encoding = \"utf-8\") as f_en, open(hi_file, encoding = \"utf-8\") as f_hi:\n",
    "    for en_sent, hi_sent in zip(f_en, f_hi):\n",
    "        en_sent = en_sent.strip()\n",
    "        hi_sent = hi_sent.strip()\n",
    "\n",
    "        total_sentences += 1\n",
    "\n",
    "        if total_sentences % 100000 == 0:\n",
    "            print(\"Sentences Processed: \", total_sentences)\n",
    "\n",
    "        if not en_sent or not hi_sent:\n",
    "            continue\n",
    "\n",
    "        doc = nlp(en_sent)\n",
    "        title_like = is_title_like(doc)\n",
    "\n",
    "        en_names = set()\n",
    "\n",
    "        # -------- English name extraction --------\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ in {\"PERSON\", \"ORG\", \"PRODUCT\", \"GPE\"}:\n",
    "                en_names.add(ent.text)\n",
    "\n",
    "        for token in doc:\n",
    "            if (\n",
    "                token.text[0].isupper()\n",
    "                and token.is_alpha\n",
    "                and len(token.text) > 2\n",
    "                and token.text.lower() not in COMMON_ENGLISH\n",
    "                and (token.i != 0 or title_like)\n",
    "            ):\n",
    "                raw_parts = re.split(r\"[\\/]\", token.text)\n",
    "                for part in raw_parts:\n",
    "                    camel_parts = split_camel_case(part)\n",
    "                    for p in camel_parts:\n",
    "                        if p.lower() not in COMMON_ENGLISH and len(p) > 2:\n",
    "                            en_names.add(p)\n",
    "\n",
    "        if not en_names:\n",
    "            continue\n",
    "\n",
    "        hi_tokens = hi_sent.split()\n",
    "\n",
    "        # -------- Alignment logic --------\n",
    "        for en_name in en_names:\n",
    "            if any(\n",
    "                part.lower() in SEMANTIC_IDENTIFIER_WORDS\n",
    "                for part in split_camel_case(en_name)\n",
    "            ):\n",
    "                continue\n",
    "            if en_name.lower() in COMMON_ENGLISH:\n",
    "                continue\n",
    "            if en_name.lower() in BAD_ENGLISH:\n",
    "                continue\n",
    "            if en_name.lower() in ENGLISH_DEMONYMS:\n",
    "                continue\n",
    "            if en_name.lower() in DIRECTIONAL_ADJECTIVES:\n",
    "                continue\n",
    "            parts = en_name.split()\n",
    "            if len(parts) > 1 and len(parts[-1]) <= 2:\n",
    "                continue\n",
    "            if is_bad_short_english(en_name):\n",
    "                continue\n",
    "            if is_plural_english(en_name):\n",
    "                continue\n",
    "            if en_name.lower() in {\"read\", \"write\", \"open\", \"close\", \"set\", \"get\"}:\n",
    "                continue\n",
    "            if is_acronym(en_name) and en_name.lower() not in {\"imap\", \"ldap\", \"smtp\", \"http\"}:\n",
    "                continue\n",
    "\n",
    "            best_match = None\n",
    "            best_score = 0.0\n",
    "\n",
    "            for hi_word in hi_tokens:\n",
    "                hi_word = normalize_hindi(hi_word)\n",
    "                \n",
    "                if hi_word in {\"पथ\", \"मार्ग\", \"नाम\", \"स्थिति\", \"संख्या\"}:\n",
    "                    continue\n",
    "                if \" \" in hi_word:\n",
    "                    continue\n",
    "                if not hi_word:\n",
    "                    continue\n",
    "                if not is_devanagari(hi_word):\n",
    "                    continue\n",
    "                if hi_word in COMMON_HINDI:\n",
    "                    continue\n",
    "                if hi_word in DEMONYM_TRANSLATIONS:\n",
    "                    continue\n",
    "                if len(hi_word) > 15:\n",
    "                    continue\n",
    "\n",
    "                hi_roman = romanize_hi(hi_word)\n",
    "\n",
    "                if (\n",
    "                    len(hi_word) <= 3\n",
    "                    and similarity(en_name, hi_roman) > 0.8\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "                if looks_like_translation(en_name, hi_word):\n",
    "                    continue\n",
    "                    \n",
    "                if len(hi_roman) > len(en_name) * 1.6:\n",
    "                    continue\n",
    "\n",
    "                if hi_roman in en_name.lower() or en_name.lower() in hi_roman:\n",
    "                    if abs(len(en_name) - len(hi_roman)) > 3:\n",
    "                        continue\n",
    "                    \n",
    "                sim = similarity(en_name, hi_roman)\n",
    "                if sim < 0.6:\n",
    "                    continue\n",
    "\n",
    "                if sim > best_score:\n",
    "                    best_score = sim\n",
    "                    best_match = hi_word\n",
    "\n",
    "            if best_score >= SIM_THRESHOLD:\n",
    "                aligned_pairs.add((\n",
    "                    en_name,\n",
    "                    best_match,\n",
    "                    round(best_score, 3)\n",
    "                ))\n",
    "\n",
    "        if len(aligned_pairs) // 500 > last_logged:\n",
    "            last_logged = len(aligned_pairs) // 500\n",
    "            print(\"Aligned pairs so far:\", len(aligned_pairs))\n",
    "\n",
    "aligned_pairs = list(aligned_pairs)\n",
    "\n",
    "print(\"Total aligned pairs: \", len(aligned_pairs))\n",
    "\n",
    "with open(\"data/processed/aligned_pairs_full.json\", \"w\", encoding = \"utf-8\") as f:\n",
    "    json.dump(aligned_pairs, f, ensure_ascii = False, indent = 2)\n",
    "\n",
    "print(\"Full dataset alignment completed\")\n",
    "print(\"Total aligned pairs: \", len(aligned_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9d214d0-1e80-4786-a3e7-ba66998db169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Laik', 'लगीं', 0.667),\n",
       " ('Tundra', 'टुण्ड्रा', 1.0),\n",
       " ('Lakshminath', 'लक्ष्मीनाथ', 0.957),\n",
       " ('xiva', 'निवास', 0.6),\n",
       " ('Sanjskrit', 'संस्कृत', 0.737),\n",
       " ('Amartya', 'अमर्त्य', 1.0),\n",
       " ('Bhagat', 'विभाग', 0.769),\n",
       " ('Maurya', 'अनुरूपा', 0.615),\n",
       " ('Hath', 'हालत', 0.6),\n",
       " ('Kashinath', 'काशीनाथ', 0.947),\n",
       " ('Marigaon', 'मारीगाँव', 0.778),\n",
       " ('Vietnamese', 'वियेतनामी', 0.7),\n",
       " ('Ishvara', 'ईश्वर', 1.0),\n",
       " ('Phani', 'रोशनी', 0.667),\n",
       " ('Dasaundha', 'दसौंधा', 0.889),\n",
       " ('Radha - Krishna', 'राधाकृष्णन', 0.8),\n",
       " ('Siddarth', 'सिद्धार्थ', 0.889),\n",
       " ('Ashvadhama', 'अश्वत्थामा', 0.857),\n",
       " ('Maksmulr', 'मैक्समूलर', 0.8),\n",
       " ('Bharat', 'बाहर', 0.833),\n",
       " ('Mardhekar', 'मर्ढेकर', 0.947),\n",
       " ('Rsabhanatha', 'ऋषभनाथ', 0.88),\n",
       " ('Trifid', 'ट्रिफिड', 0.714),\n",
       " ('Aitrai', 'ऐतरेय', 0.714),\n",
       " ('Ashtanga', 'अष्टांग', 0.875),\n",
       " ('Duggar', 'डोगरा', 0.667),\n",
       " ('Greville', 'ग्रेविल्ले', 1.0),\n",
       " ('Sabha', 'सहयोगी', 0.615),\n",
       " ('Raima Sen', 'राइमा', 0.714),\n",
       " ('Ramma', 'रात', 0.667),\n",
       " ('Bahadur', 'बहुत', 0.615),\n",
       " ('Changanacherry', 'चंगनाशेरी', 0.741),\n",
       " ('Juang', 'जुआंगों', 0.667),\n",
       " ('Inter', 'मित्र', 0.6),\n",
       " ('Naldera', 'नालडेरा', 0.933),\n",
       " ('Aleksandr', 'अलेक्सान्द्र', 0.947),\n",
       " ('Bangladesh', 'बाँग्लादेश', 0.909),\n",
       " ('Milligram', 'मिलिग्राम', 0.889),\n",
       " ('Turkomen', 'तुर्कमेन', 0.824),\n",
       " ('Abdul', 'अब्दुतल', 0.769),\n",
       " ('Private', 'प्रस्तु', 0.615),\n",
       " ('Canadian', 'कैनाडी', 0.667),\n",
       " ('Antyodaya', 'अन्तोकदय', 0.842),\n",
       " ('Amarawati', 'अमरावती', 0.889),\n",
       " ('Pluto', 'प्लूटो', 1.0),\n",
       " ('Deendayal', 'दीनदयाल', 0.737),\n",
       " ('Tunguska', 'तुंगुस्का', 0.875),\n",
       " ('Vythi', 'व्यथि', 0.909),\n",
       " ('Lalo', 'लालो', 1.0),\n",
       " ('Moulali', 'मौलाली', 0.857),\n",
       " ('Goheen', 'गोहीन', 0.667),\n",
       " ('Ratha', 'कहा', 0.667),\n",
       " ('Rustom', 'रुस्तम', 0.769),\n",
       " ('Tilak', 'तक', 0.667),\n",
       " ('Naujawan', 'नवजवान', 0.667),\n",
       " ('Lamahi', 'लमही', 1.0),\n",
       " ('Hijra', 'हिजड़ा', 0.667),\n",
       " ('Sanskrit', 'सरकारी', 0.625),\n",
       " ('Warhol', 'वारहोल', 0.714),\n",
       " ('Mural', 'और', 0.667),\n",
       " ('Katdare', 'कटदरे', 0.933),\n",
       " ('Bathymetric', 'बेथीमेट्रिक', 0.696),\n",
       " ('Escherichia', 'एशिरिशिया', 0.727),\n",
       " ('Among', 'टांगे', 0.6),\n",
       " ('Sanctuary', 'सौंदर्य', 0.667),\n",
       " ('Vanuatu', 'वानूअतु', 1.0),\n",
       " ('Midland', 'मिडलैंड', 0.706),\n",
       " ('Balluka', 'बल्लुका', 1.0),\n",
       " ('neutron', 'न्यूट्रान', 0.667),\n",
       " ('Raheja', 'रहेजा', 1.0),\n",
       " ('Ninevah', 'निनेवह', 0.933),\n",
       " ('Katsura', 'कतसूरा', 0.933),\n",
       " ('Manchuria', 'मांचुरिया', 0.842),\n",
       " ('IPv6', 'आईपीवी', 0.6),\n",
       " ('Tenant Act', 'ठेनन्ट्', 0.706),\n",
       " ('Marr', 'मार', 0.75),\n",
       " ('Prafullchand', 'प्रफुल्लचंद्र', 0.714),\n",
       " ('Kalyana', 'कल्याण', 1.0),\n",
       " ('Metanetwork', 'मेटानेटवर्क', 0.75),\n",
       " ('Rachao', 'बचाव', 0.615),\n",
       " ('Bentik', 'बैन्टिक', 0.714),\n",
       " ('Upanishad', 'केनोपनिषद्', 0.762),\n",
       " ('Sarand', 'सारान्दे', 0.923),\n",
       " ('Air', 'आर', 0.667),\n",
       " ('Dawoodi', 'दवूदि', 0.615),\n",
       " ('Mulaipal', 'मुलैपाल', 0.941),\n",
       " ('Sonnet', 'सोनेट', 0.833),\n",
       " ('Shortughai', 'श्रोतुघायी', 0.857),\n",
       " ('Morrison', 'मारिसन', 0.625),\n",
       " ('Multiplexer', 'मल्टीप्लेक्सर', 0.667),\n",
       " ('Mahiwal', 'माहीवाल', 0.8),\n",
       " ('Namgyel', 'नामग्याल', 0.75),\n",
       " ('Uttama', 'उत्तत', 0.833),\n",
       " ('Siddhendra', 'सिद्वेन्द्र', 0.842),\n",
       " ('Natake', 'नाटकें', 0.923),\n",
       " ('Mehrauli', 'मरहौली', 0.706),\n",
       " ('Nirgun', 'निरगुन', 0.857),\n",
       " ('Qalaid', 'कलैद', 0.769),\n",
       " ('Swathi', 'स्वाति', 0.727),\n",
       " ('Sabirin', 'सब्र', 0.667),\n",
       " ('Aoni - Baoni', 'ओवोनीबावोनी', 0.696),\n",
       " ('Wheatstone', 'व्हीटस्टोन', 0.6),\n",
       " ('Deigital', 'डिजिटल', 0.75),\n",
       " ('Halayudha', 'हलायुध', 1.0),\n",
       " ('Gachchame', 'गच्छामि', 0.889),\n",
       " ('Abhiyaanand', 'अभियान', 0.842),\n",
       " ('Balabhadra', 'बळभद्रदेव', 0.833),\n",
       " ('Padak', 'प्रदान', 0.667),\n",
       " ('Viralur', 'विरालूर', 0.933),\n",
       " ('Back', 'ब्लैक', 0.6),\n",
       " ('Jalatund', 'जलातुंड', 0.824),\n",
       " ('Dilip', 'दिलिप', 0.909),\n",
       " ('Bharathiar', 'भारतियर', 0.857),\n",
       " ('Bkagavat', 'भागवत', 0.824),\n",
       " ('Subbaraya', 'सुब्बराय', 1.0),\n",
       " ('Austen', 'औस्टिन', 0.769),\n",
       " ('Joshimath', 'जोशीमठ', 0.947),\n",
       " ('Start', 'सौर', 0.6),\n",
       " ('Ayn Rand', 'आयन', 0.615),\n",
       " ('Orissa', 'क्रिसमस', 0.667),\n",
       " ('Pradhan', 'प्रबंधन', 0.778),\n",
       " ('Jatibhashavijr', 'जातिभाषाविज्ञान', 0.812),\n",
       " ('Kramrisch', 'क्रैमरिश', 0.8),\n",
       " ('madrasa', 'मदरसा', 0.933),\n",
       " ('Gilanian', 'गीलानायाँ', 0.778),\n",
       " ('Namasami', 'नामासामी', 1.0),\n",
       " ('Rani', 'अपनी', 0.667),\n",
       " ('Ernie', 'अर्नी', 0.667),\n",
       " ('Algeria', 'अल्जीरिया', 0.667),\n",
       " ('Sanskritized', 'संस्कृत', 0.636),\n",
       " ('Fakir', 'फ़क़ीर', 0.727),\n",
       " ('Dwaparyoug', 'द्वापरयुग', 0.762),\n",
       " ('Mohato', 'मोहातो', 1.0),\n",
       " ('May', 'मै', 0.667),\n",
       " ('Sama', 'भस्म', 0.6),\n",
       " ('Gettext', 'गेटटेक्स्ट', 0.706),\n",
       " ('Jataka', 'जाते', 0.6),\n",
       " ('Kamaraj', 'कामराज', 0.933),\n",
       " ('Austric', 'आस्टरिक', 0.667),\n",
       " ('Qurah', 'क़ुरआन', 0.667),\n",
       " ('Rashtrapati Bhavan', 'राष्ट्रपतिकाल', 0.788),\n",
       " ('Romain', 'रोमेन', 0.667),\n",
       " ('Deepshikha', 'दीपशिखा', 0.8),\n",
       " ('Janata', 'बात', 0.6),\n",
       " ('Malacca', 'मलैका', 0.714),\n",
       " ('nritya', 'नृत्य', 0.923),\n",
       " ('Ramulu', 'रामुलु', 1.0),\n",
       " ('Mombaien', 'मोम्बाइयेन', 0.889),\n",
       " ('Eurovision', 'यूरोविज़न', 0.6),\n",
       " ('Hanoi', 'है।', 0.667),\n",
       " ('Manipaala', 'मणिपाला', 0.941),\n",
       " ('Gornergrat', 'गार्नरग्रेट', 0.636),\n",
       " ('Shivpuri', 'शिवपुरी', 0.941),\n",
       " ('Gladiator', 'ग्लैडीटोरिअम', 0.727),\n",
       " ('Khorana', 'खुराना', 0.857),\n",
       " ('Rajapur', 'राजापुर', 0.933),\n",
       " ('Qatar', 'क़ॉतार', 0.833),\n",
       " ('Araththurai', 'आरातुरई', 0.842),\n",
       " ('Dakshinamoorthy', 'दक्षिणामूर्ति', 0.786),\n",
       " ('Bhatt', 'भट्ट', 0.909),\n",
       " ('Kondadi', 'कोंडाडी', 0.857),\n",
       " ('Nrsimha', 'नृसिंह', 0.875),\n",
       " ('Their', 'साथी', 0.6),\n",
       " ('Jatinga', 'जतिंगा', 0.857),\n",
       " ('Shah', 'कोश', 0.667),\n",
       " ('Pan Card', 'पैन', 0.615),\n",
       " ('Drive', 'ड्राइव', 0.727),\n",
       " ('Bibighar', 'बीबीघर', 0.941),\n",
       " ('Siamese', 'इनमें', 0.615),\n",
       " ('Snoop', 'स्नुप', 0.6),\n",
       " ('Pane', 'पैन', 0.667),\n",
       " ('There', 'चेहरे', 0.667),\n",
       " ('Universite', 'यूनिवर्सिटी', 0.762),\n",
       " ('Kabya', 'काव्य।', 0.727),\n",
       " ('Calar', 'कलार', 0.727),\n",
       " ('Subhagwati', 'सुभागवती', 0.857),\n",
       " ('Ashwin', 'आश्विन', 0.769),\n",
       " ('Limpopo', 'लिम्पोपो', 1.0),\n",
       " ('Europa', 'यूरोप', 0.833),\n",
       " ('Rama', 'आराम', 0.889),\n",
       " ('Matangesvara', 'पिरवतनेश्वर', 0.714),\n",
       " ('Valinokkam', 'रामनोक्क्म', 0.6),\n",
       " ('Sharaabi', 'शराबी', 0.933),\n",
       " ('Transudative', 'ट्रांस्यूडेटिव', 0.72),\n",
       " ('Israel', 'जिसे', 0.6),\n",
       " ('Puranid', 'पौराणिक', 0.75),\n",
       " ('Wahadat - ul - Wajud', 'वहदतउलवजूद', 0.649),\n",
       " ('Gotra', 'सगोत्र', 0.833),\n",
       " ('Raga Kalpadruma', 'कालपाद्रुम', 0.769),\n",
       " ('Supaul', 'साल', 0.6),\n",
       " ('Ssidhanto', 'सिद्धांतों', 0.737),\n",
       " ('Hurriyat', 'ह्र्रियत', 0.875),\n",
       " ('Muttahida', 'मुत्तहिदा', 1.0),\n",
       " ('Vaishnava', 'आहवान', 0.625),\n",
       " ('Ismail', 'इस्माईल', 0.923),\n",
       " ('Chandanyai', 'ठण्डी', 0.625),\n",
       " ('Rajan', 'राजन', 0.909),\n",
       " ('Amara', 'नगर', 0.727),\n",
       " ('Avul Pen', 'आवुलपेन', 0.824),\n",
       " ('Uraemic', 'यूरेमी', 0.769),\n",
       " ('Reconquista', 'रिक़ोन्कीसता', 0.636),\n",
       " ('S. R. Khastgir', 'खास्तगीर', 0.667),\n",
       " ('Intranet', 'अंतरानेट', 0.667),\n",
       " ('Batsar', 'बत्सर', 0.923),\n",
       " ('Sujan Rai', 'सुजान', 0.8),\n",
       " ('Kala', 'अकारा', 0.667),\n",
       " ('Bahaduri', 'भादुड़ी', 0.75),\n",
       " ('Capable', 'आपके', 0.667),\n",
       " ('Hembram', 'हेम्ब्रम', 0.933),\n",
       " ('Mandapam', 'मंडपम', 0.824),\n",
       " ('Kirgizia', 'किर्गिज़िआ', 1.0),\n",
       " ('Karlsruhe', 'कार्लश्रुहे', 0.9),\n",
       " ('Vasco', 'वास्को', 0.8),\n",
       " ('Purna', 'संपूर्ण', 0.769),\n",
       " ('Kumara Sambhava', 'कुमारसंभव', 0.966),\n",
       " ('Nicholson', 'निकोल्सन', 0.667),\n",
       " ('Tirap', 'तिराप', 0.909),\n",
       " ('Shankar Jaikishan', 'शंकरजयकिशन', 0.778),\n",
       " ('Peravia', 'पेराविया', 0.933),\n",
       " ('Budhadev Bose', 'बुद्धदेव', 0.696),\n",
       " ('Gas', 'घ', 0.667),\n",
       " ('Bjornson', 'ब्जोर्नसन', 0.778),\n",
       " ('Salman', 'सलमान', 0.857),\n",
       " ('Farkka', 'फरक्का', 0.714),\n",
       " ('SagarKhedu', 'सागरखेडु', 0.952),\n",
       " ('Masjid', 'मस्जिदें', 0.857),\n",
       " ('Vardhak', 'वारटक', 0.667),\n",
       " ('Pyil', 'पैल', 0.667),\n",
       " ('Ushd', 'उषा', 0.75),\n",
       " ('Buta', 'बूटा', 1.0),\n",
       " ('Shiva', 'विष', 0.6),\n",
       " ('Bolangir', 'बोलंगीर', 0.824),\n",
       " ('Maria', 'मारिया।', 0.833),\n",
       " ('Philippine Peso', 'फिलिप्पीन्स', 0.769),\n",
       " ('Keladi', 'केलादि', 1.0),\n",
       " ('Opus', 'ओपस', 0.667),\n",
       " ('Rule', 'रूपये', 0.6),\n",
       " ('Chowrashi', 'चौरासी', 0.706),\n",
       " ('Semester', 'सेमेस्टर', 0.824),\n",
       " ('Dorairajan', 'दोरईराजन', 0.952),\n",
       " ('Alan', 'एलन', 0.667),\n",
       " ('Rank', 'रक्षा', 0.6),\n",
       " ('Arusha', 'अरुषा', 1.0),\n",
       " ('Sacco', 'सैको', 0.6),\n",
       " ('Vanganga', 'वाणगंगा', 0.824),\n",
       " ('Mandali', 'मडंली', 0.857),\n",
       " ('Ganje', 'गंज', 0.6),\n",
       " ('Azimabadi', 'अजीमाबादी', 0.889),\n",
       " ('Sukarmalla', 'सुकरमल्ला', 0.952),\n",
       " ('DOMString', 'डीओएमस्ट्रिंग', 0.727),\n",
       " ('Khawaja', 'खवाजा', 0.857),\n",
       " ('India', 'दीप्त', 0.6),\n",
       " ('Hicham', 'हिशम', 0.769),\n",
       " ('Europe / Bucharest', 'यूरोपबुखारेस्ट', 0.706),\n",
       " ('Sahuf', 'सहूफ़', 0.909),\n",
       " ('Hoplolaimid', 'हॉप्लोलैमिड', 0.833),\n",
       " ('Selvanathan', 'सेल्वनाथन', 0.957),\n",
       " ('Adept', 'अडेप्ट', 0.909),\n",
       " ('Atal', 'निपट', 0.6),\n",
       " ('Satanic', 'शांत', 0.615),\n",
       " ('Shaikh', 'शाह', 0.727),\n",
       " ('Maryland', 'आर्यलॅड', 0.667),\n",
       " ('Mimosa', 'मिनेडोसा', 0.714),\n",
       " ('Apulia', 'अपुलिया', 0.923),\n",
       " ('Sukesha', 'सुकेशा', 1.0),\n",
       " ('Lund', 'लौड़ा', 0.6),\n",
       " ('Sarc', 'सार्क', 0.667),\n",
       " ('Varaha', 'नंवराह', 0.8),\n",
       " ('Dayaramthe', 'दयाराम', 0.778),\n",
       " ('Dadoba', 'दादोबा', 1.0),\n",
       " ('Belgachhia', 'गछिया', 0.706),\n",
       " ('Desabhandu', 'देशबन्धु', 0.857),\n",
       " ('Quranic', 'कुरानी', 0.769),\n",
       " ('Mass', 'मास', 0.75),\n",
       " ('maheshwara', 'महेश्वर', 0.9),\n",
       " ('Sohlman', 'श्रीमान', 0.667),\n",
       " (\"Sher Shah'\", 'शेरशाह', 0.8),\n",
       " ('Chhabya', 'छव्या', 0.769),\n",
       " ('Mins', 'मिनट', 0.6),\n",
       " ('Venkatarayadu', 'वेंकटराय', 0.833),\n",
       " ('Kashmere', 'कश्मीरी', 0.75),\n",
       " ('M. Visvesvarya', 'विश्वेश्वरैया', 0.759),\n",
       " ('Kuusenln', 'कूसेनिन', 0.75),\n",
       " ('Chingola', 'चिंगोला', 0.875),\n",
       " ('Iberian', 'इबेरिया', 0.857),\n",
       " ('Development', 'डेवेलेपमेंट', 0.75),\n",
       " ('Sringara Vilasa', 'शृड्गारविलास', 0.839),\n",
       " ('Hinduism', 'हिंदू', 0.615),\n",
       " ('Readership', 'रीडरशिप', 0.667),\n",
       " ('Samuel', 'सामने', 0.667),\n",
       " ('Goraya', 'गोरया', 1.0),\n",
       " ('Marwar', 'कर', 0.6),\n",
       " ('Baje', 'बाजे', 1.0),\n",
       " ('Kannappan', 'कण्णप्पन', 0.947),\n",
       " ('pana - khil', 'पानखील', 0.8),\n",
       " ('Jiro', 'जीरो', 1.0),\n",
       " ('Rasa', 'रखा', 0.667),\n",
       " ('Bustard', 'बर्स्टड', 0.667),\n",
       " ('Mackintosh', 'मैकिन्टौश', 0.727),\n",
       " ('Thanjam', 'तंजम', 0.714),\n",
       " ('Too', 'ऑटो', 0.667),\n",
       " ('Assisi', 'असिसी', 0.909),\n",
       " ('Mudrarakshasa', 'मुद्रारक्षस।', 0.963),\n",
       " ('Chaarbaag', 'चारबाग', 0.778),\n",
       " ('Rajasevasakta', 'राजसेवक', 0.783),\n",
       " ('Qaeda', 'जेड', 0.667),\n",
       " ('Shahpur', 'शाहपुर', 0.875),\n",
       " ('Sundari', 'पुजारी', 0.615),\n",
       " ('Saire', 'सैरे', 1.0),\n",
       " ('Jal Sinchan', 'सिंचन', 0.632),\n",
       " ('Binod', 'विनोद', 0.727),\n",
       " ('Balkoba', 'बालकोबा', 0.933),\n",
       " ('Tumharau', 'तुम्हारौ', 1.0),\n",
       " ('Andhra Pradesh', 'आन्ध्रप्रदेश', 0.929),\n",
       " ('the Brahmo Samaj', 'ब्रहमोसमाज', 0.759),\n",
       " ('Guruprasada', 'गुरुप्रसाद', 1.0),\n",
       " ('Abaya', 'अबाया', 1.0),\n",
       " ('Hath', 'साथी', 0.667),\n",
       " ('Avtarvad', 'अवतारवाद', 0.842),\n",
       " ('Magudi', 'मागुडी', 1.0),\n",
       " ('Guelph', 'गुएल्फ', 0.923),\n",
       " ('Penal', 'प्रेस', 0.6),\n",
       " ('Gurumukhi', 'गुरूमुखी', 1.0),\n",
       " ('Oyyarath', 'ओय्यारत', 0.875),\n",
       " ('Imam', 'इसमें', 0.6),\n",
       " ('Tare', 'तारे', 1.0),\n",
       " ('Kavikarnapura', 'कर्णपुरकृत', 0.643),\n",
       " ('Yandaboo', 'यंडाबू', 0.667),\n",
       " ('Rishwat', 'रिश्वत', 0.8),\n",
       " ('Dharmender', 'धर्मेन्द्र', 0.9),\n",
       " ('Final', 'फाइनल', 0.615),\n",
       " ('Noah', 'नोआह', 0.889),\n",
       " (\"Al-Ma'un\", 'अलमाउन', 0.75),\n",
       " ('Worcester', 'वार्चेस्टर', 0.6),\n",
       " ('Enhancement', 'एन्हांसमेंट', 0.609),\n",
       " ('Catalan', 'केटालन', 0.667),\n",
       " ('Benaam', 'बेनाम', 0.833),\n",
       " ('Aligad', 'अलीगढ', 0.857),\n",
       " ('ishkuman', 'इशकुमान', 0.889),\n",
       " ('Villin', 'विलिन', 0.833),\n",
       " ('Lachaise', 'लाचेज़', 0.667),\n",
       " ('Surbahar', 'सुरबहार', 0.889),\n",
       " ('Shreedhar', 'श्रीधर', 0.778),\n",
       " ('Osama', 'समय', 0.727),\n",
       " ('Jahandar Shah', 'जहाँदार', 0.783),\n",
       " ('Bolsonaro', 'बोलोनसरो', 0.842),\n",
       " ('Shwetamber', 'श्वेताम्बर', 0.762),\n",
       " ('Turkomen', 'तुर्क़मेन', 0.706),\n",
       " ('Fastag', 'फास्टैग', 0.667),\n",
       " ('Hashemite', 'हाश्मिते', 0.941),\n",
       " ('Leonor', 'लेओनोर', 0.923),\n",
       " ('Datura', 'मन्दार', 0.615),\n",
       " ('Hunny', 'हन्नी', 0.6),\n",
       " ('Gurudwara', 'गुरुद्वारे', 0.778),\n",
       " ('Deposit', 'डिपोजिट', 0.667),\n",
       " ('Avram', 'एवरम', 0.667),\n",
       " ('Military', 'मिल', 0.667),\n",
       " ('Distemper', 'डिस्टेंपर', 0.842),\n",
       " ('Marshal', 'मार्शल', 0.933),\n",
       " ('Visveswarayya', 'विश्वेश्वरैया', 0.786),\n",
       " ('Fitna', 'ट्रेन', 0.6),\n",
       " ('Kuczynski', 'कुज्यास्की', 0.706),\n",
       " ('Haskovo', 'हैकोऊ', 0.615),\n",
       " ('Essonne', 'एसोन्ने', 0.923),\n",
       " ('Akasavani', 'आकाशवाणी', 0.947),\n",
       " ('Basava', 'बाट', 0.6),\n",
       " ('Jaya', 'उजास', 0.667),\n",
       " ('Yojana', 'योजनाकी', 0.857),\n",
       " ('tokyo', 'तोकियो', 0.909),\n",
       " ('Arunachal', 'अरुणचल', 0.947),\n",
       " ('Balayogi', 'बालयोगी', 1.0),\n",
       " ('Bareilly', 'बरेलीके', 0.625),\n",
       " ('Sinusoidal', 'साइनुसाइडल', 0.818),\n",
       " ('Sidney', 'सिडनी', 0.667),\n",
       " ('Nazarene', 'नसरानी', 0.625),\n",
       " ('Gondwana', 'गोडवाना', 0.75),\n",
       " ('Todd Martin', 'मार्टिन', 0.667),\n",
       " ('Breast', 'ब्रेस्ट', 0.833),\n",
       " ('Written', 'ब्रिटेन', 0.714),\n",
       " ('Gangtok', 'गंग्टोक', 0.8),\n",
       " ('There', 'उठे', 0.667),\n",
       " ('Correa', 'कोर्रेया', 0.769),\n",
       " ('Ashoka', 'भाषा', 0.667),\n",
       " ('Agnon', 'अग्नोन', 0.909),\n",
       " ('Yuan', 'यूआं', 0.75),\n",
       " ('Nigam', 'निगम', 0.909),\n",
       " ('Samui', 'सामोई', 0.8),\n",
       " ('Magazine', 'मैगज़ीन', 0.824),\n",
       " ('Jayaram', 'जयराम', 0.933),\n",
       " ('Whetstone', 'ह्वेटस्टोन', 0.737),\n",
       " ('Sample', 'वाले', 0.6),\n",
       " ('Sant', 'बँटे', 0.6),\n",
       " ('Space', 'पांचवे', 0.615),\n",
       " ('Keithahn', 'कीथन', 0.8),\n",
       " ('Buckinghamshire', 'बकिंघमशायर', 0.625),\n",
       " ('Bishrampur', 'विश्रामपुर', 0.818),\n",
       " ('Ghadshi', 'घडशी', 0.933),\n",
       " ('Pali', 'प्रति', 0.667),\n",
       " ('Lochia', 'लोकिया', 0.667),\n",
       " ('Poornath', 'पूर्णात', 0.667),\n",
       " ('hamirpur', 'हमीरपुर', 0.889),\n",
       " ('Khas', 'रखा', 0.667),\n",
       " ('Doklah', 'ढोकला', 0.769),\n",
       " ('Based', 'रास्ते', 0.6),\n",
       " ('Salaya', 'जल', 0.6),\n",
       " ('Vaicharik', 'वैचरिक', 0.947),\n",
       " ('Nagercoil', 'नागरकोइल', 0.7),\n",
       " ('Lakshmana', 'रामलक्ष्मण', 0.818),\n",
       " ('Girija', 'गिरिजा', 1.0),\n",
       " ('Earner', 'करने', 0.667),\n",
       " ('Beedi', 'बीडी', 0.667),\n",
       " ('Cona', 'त्शोना', 0.6),\n",
       " ('Kadambri', 'कादंबरी', 0.941),\n",
       " ('Goethe', 'ग्वेते', 0.727),\n",
       " ('Gakhal', 'गखाल', 0.923),\n",
       " ('Nagpara', 'नाग', 0.727),\n",
       " ('Development', 'डेवलेपमेन्ट', 0.75),\n",
       " ('Narbada', 'नर्बदा', 1.0),\n",
       " ('Shankar', 'इसका', 0.667),\n",
       " ('AatmNirbharta', 'आत्मनिर्भर', 0.88),\n",
       " ('Mini', 'मिनी', 1.0),\n",
       " ('Nagrani', 'नागाराणी', 0.933),\n",
       " ('Ratnagiri', 'रत्नगिरी', 1.0),\n",
       " ('Sharaf', 'स्वर', 0.727),\n",
       " ('Jogalelar', 'जोगळेकर', 0.842),\n",
       " ('Kollagame', 'कोलागेम', 0.706),\n",
       " ('Siddique', 'सिद्दीक़े', 0.933),\n",
       " ('Avyaya - kosha', 'अव्ययकोश', 0.88),\n",
       " ('Jamana', 'ज़माना', 0.833),\n",
       " ('Nath', 'हाथ', 0.667),\n",
       " ('Werner', 'वेर्नर', 0.615),\n",
       " ('Alone', 'लोगे।', 0.6),\n",
       " ('Soloman', 'सोलोमन', 0.933),\n",
       " ('Subbalakshmi', 'सुब्बालक्ष्मी', 1.0),\n",
       " ('Kibbar', 'किब्बर', 0.923),\n",
       " ('Adnan', 'अनजाने', 0.667),\n",
       " ('Madarsa', 'मदरसा', 0.933),\n",
       " ('Gasoline', 'गैसोलीन', 0.824),\n",
       " ('Kandi', 'कंदी', 0.8),\n",
       " ('Panchayat Raj', 'पंचायत', 0.783),\n",
       " ('Dmitry', 'दिमित्री', 0.769),\n",
       " ('Gurbax Singh', 'गुरबक्श', 0.636),\n",
       " ('Riccardo', 'रिक्कर्डो', 0.75),\n",
       " ('District', 'डीटीओ', 0.615),\n",
       " ('Saugor', 'सौगोर', 0.923),\n",
       " ('Fujita', 'फुजिता', 0.769),\n",
       " ('Bhandeswar', 'भंडेश्वर', 0.727),\n",
       " ('Konkan', 'कोंकन', 0.769),\n",
       " ('Kathakali', 'कथाकली', 1.0),\n",
       " ('Lhasa', 'हिंसा', 0.6),\n",
       " ('Philippine', 'फिलिप्पीन्स', 0.857),\n",
       " ('Markham', 'मरखम', 0.875),\n",
       " ('Dandi', 'दांडी।', 0.727),\n",
       " ('Shrikrshna', 'कृष्ण', 0.667),\n",
       " ('Matagami', 'मातागामी', 1.0),\n",
       " ('Rachakonda', 'राचकोंड', 0.9),\n",
       " ('Ramavataram', 'रामावतारम्', 1.0),\n",
       " ('Margao', 'मारगाओ', 0.923),\n",
       " ('A. Acutan', 'अच्युतन', 0.667),\n",
       " ('Nevada', 'नेवादा', 1.0),\n",
       " ('Panel', 'आपने', 0.8),\n",
       " ('Katyusha', 'कैटीउषा', 0.824),\n",
       " ('MetaNetwork', 'मेटानेटवर्क', 0.75),\n",
       " ('Paran', 'करने', 0.727),\n",
       " ('Own', 'ओन', 0.667),\n",
       " ('Navajo', 'नावाहो', 0.833),\n",
       " ('Pereira', 'परेरा', 0.615),\n",
       " ('Gujarati', 'जाती', 0.667),\n",
       " ('Ganga', 'घने', 0.6),\n",
       " ('Paniker', 'पणिक्कर', 0.75),\n",
       " ('Saville', 'सेविल', 0.615),\n",
       " ('Sautramani', 'सौत्रामणी', 1.0),\n",
       " ('Kunzaru', 'कुंजरु', 0.714),\n",
       " ('Kids', 'किसी', 0.75),\n",
       " ('Array', 'और', 0.667),\n",
       " ('Yoruba', 'योरुबा', 1.0),\n",
       " ('Jetpura', 'जेतपुरा', 0.933),\n",
       " ('Lanchester', 'लानचेस्टर', 0.818),\n",
       " ('Naphthalene', 'नैप्थलीन', 0.727),\n",
       " ('Vrundavati', 'वृन्दावती', 0.857),\n",
       " ('Bhavan', 'भारती', 0.615),\n",
       " ('Kudala Sangama', 'कुदालसंगम।', 0.857),\n",
       " ('Macedonia', 'मैसेदोनिया', 0.8),\n",
       " ('Allah', 'जल्द', 0.6),\n",
       " ('Rhenagold', 'रहेनगोल्ड', 0.9),\n",
       " ('Buddhist', 'बौदेध', 0.625),\n",
       " ('Bharata', 'सकता', 0.615),\n",
       " ('Eliza', 'एज़िजा', 0.6),\n",
       " ('Progreso', 'प्रोग्रेसो', 1.0),\n",
       " ('Korba', 'कोरबाओं', 0.769),\n",
       " ('Balaram', 'बालाराम', 0.933),\n",
       " ('muhabbat', 'मुहब्बत।', 0.889),\n",
       " ('Bharatchandra Ray', 'भारतचंद्र', 0.774),\n",
       " ('Arke', 'आर्के', 1.0),\n",
       " ('Arasu', 'आरासु', 1.0),\n",
       " ('Mulashi', 'मुळशी', 1.0),\n",
       " ('Dipa Karmakar', 'कर्मकार', 0.727),\n",
       " ('Rothera', 'रोथेरा', 1.0),\n",
       " ('Kahiye', 'कहिये।', 0.923),\n",
       " ('Ankuraand', 'अंकुर', 0.667),\n",
       " ('Balappagouda', 'बल्लप्प', 0.7),\n",
       " ('Visakhapalnam', 'विशाखापत्तनम', 0.8),\n",
       " ('Murder', 'मर्डर', 0.615),\n",
       " ('Rehman Rahi', 'रहमान', 0.632),\n",
       " ('Jahan', 'माह', 0.667),\n",
       " ('Special', 'स्पैन', 0.615),\n",
       " ('Arabia', 'पूरब', 0.667),\n",
       " ('Lot', 'लो', 0.8),\n",
       " ('Kalwa', 'कालवा', 0.727),\n",
       " ('Bipin Babu', 'विपिन', 0.625),\n",
       " ('Turner', 'टर्नर', 0.615),\n",
       " ('Thavar', 'ठाकरे', 0.769),\n",
       " ('Bhagavatar', 'भागवतार', 0.952),\n",
       " ('Dooni', 'दूनी', 0.667),\n",
       " ('Bickley', 'बिकली', 0.615),\n",
       " ('Union', 'कम्युनिओ', 0.615),\n",
       " ('Factorial', 'फैक्टोरियल', 0.636),\n",
       " ('Amrasca', 'कपास', 0.615),\n",
       " ('Suraksha', 'शिक्षा', 0.667),\n",
       " ('Tabuk', 'तक', 0.667),\n",
       " ('John Rossoli', 'रॉस्सोली', 0.6),\n",
       " ('Tuukka', 'टुक्का', 0.909),\n",
       " ('Rand', 'रहना', 0.6),\n",
       " ('Orban', 'ओरबान', 0.833),\n",
       " ('Mahjongg', 'महजोंग', 0.706),\n",
       " ('Brahmin', 'ब्राह्यण', 0.667),\n",
       " ('Krishan', 'हरकिशन', 0.667),\n",
       " ('Pradeep', 'प्रदीप', 0.714),\n",
       " ('Bandur', 'बन्दूर', 0.923),\n",
       " ('Sharatchan', 'शरतचन्द्र', 0.833),\n",
       " ('Khorugh', 'ख़ोरूग़', 0.769),\n",
       " ('Athaba', 'अथबा', 1.0),\n",
       " ('Mrinalini Devi', 'मृणालिनी', 0.75),\n",
       " ('Tour', 'टूर', 0.75),\n",
       " ('Petrovna', 'पेट्रोवना', 0.941),\n",
       " ('Chamberlain', 'चैम्बरलेनकी', 0.615),\n",
       " ('Gaya', 'लगाया', 0.8),\n",
       " ('Daman', 'कम्पनी', 0.667),\n",
       " ('Fargo', 'फार्गो', 0.727),\n",
       " ('Dasharatha', 'दशरथ', 1.0),\n",
       " ('Narela', 'नरेल', 1.0),\n",
       " ('Dogo', 'डोगो', 1.0),\n",
       " ('Maharashtra', 'महामहीम', 0.667),\n",
       " ('Zinta', 'जिंटा', 0.6),\n",
       " ('Bowbazar', 'बोउबाज़ार', 0.824),\n",
       " ('Raghunatha', 'रघुनाथ', 1.0),\n",
       " ('Samhita', 'मंत्र', 0.615),\n",
       " ('Canacona', 'काणकोण', 0.75),\n",
       " ('Kokcha', 'कोकचा', 0.923),\n",
       " ('Ahlawat', 'अहलावत', 0.75),\n",
       " ('Rama', 'रामजी', 0.8),\n",
       " ('Loiano', 'लोइयानो', 0.923),\n",
       " ('Bandhavgarh', 'बांधवगढ', 0.75),\n",
       " ('Held', 'हेल्ड', 0.889),\n",
       " ('Rajendra', 'राजेंन्द्र', 0.941),\n",
       " ('Bhibhatsa', 'वीभत्स', 0.824),\n",
       " ('Bidar', 'बिदार', 0.909),\n",
       " ('Ernest', 'अर्नेस्ट', 0.769),\n",
       " ('Anantanarayanan', 'नारायणन।', 0.692),\n",
       " ('Karzai', 'करजई', 0.769),\n",
       " ('Gune', 'गुणे', 1.0),\n",
       " ('Akbar', 'आगरा', 0.6),\n",
       " ('Khoje', 'खोजे', 1.0),\n",
       " ('Sahitya', 'सत्य', 0.833),\n",
       " ('Rate', 'करती', 0.6),\n",
       " ('Kamboj', 'काम्बोज', 0.923),\n",
       " ('Bombarinding', 'बमबारी', 0.6),\n",
       " ('Bhim', 'बाहरी', 0.6),\n",
       " ('Hobo', 'होबो', 1.0),\n",
       " ('Dharma', 'आधार', 0.833),\n",
       " ('Balasubrahmanyam', 'बालासुब्रमण्यम', 0.938),\n",
       " ('Hyperemia', 'हाइपरएमिया', 0.667),\n",
       " ('Moradabad', 'मुरादाबाद', 0.842),\n",
       " ('Bhalerao', 'भालेराव', 0.824),\n",
       " ('Dashakumara - charita', 'दशकुमारचरित', 0.923),\n",
       " ('Tatsuhei', 'तातसूहेइ', 0.941),\n",
       " ('Ladak', 'लद्दाख़', 0.833),\n",
       " ('Sahib', 'साहिबा', 0.909),\n",
       " ('Chamarajendra', 'रीचामराजेन्द्र', 0.929),\n",
       " ('Dieng', 'दींग', 0.6),\n",
       " ('Brahmaverg', 'ब्रह्मवर्ग', 0.857),\n",
       " ('Railway', 'राइट्स', 0.615),\n",
       " ('Channel', 'हमने', 0.615),\n",
       " ('Kumaram', 'कुमराम', 0.933),\n",
       " ('Vaktak', 'तक', 0.6),\n",
       " ('Gaudapada', 'गौड़ापाद', 0.947),\n",
       " ('tachanid', 'टैकनिड', 0.706),\n",
       " ('Isaura', 'इजौरा', 0.833),\n",
       " ('Jjia', 'जज़िया', 0.6),\n",
       " ('Have', 'चालें', 0.6),\n",
       " ('Inle', 'इन्ले', 1.0),\n",
       " ('Cervisia', 'सर्विसिया', 0.706),\n",
       " ('Economist', 'इकोनोमिस्ट', 0.737),\n",
       " ('Keillor', 'कीलर', 0.615),\n",
       " ('Qureshi', 'कुरेशी', 0.857),\n",
       " ('Gaudugitamu', 'गोडुगीतामु', 0.857),\n",
       " ('Hasik', 'हासिक', 0.909),\n",
       " ('Orathanadu', 'ओरथनाडु', 1.0),\n",
       " ('Danu - Kabandha', 'दनुकबन्ध', 0.889),\n",
       " ('sharang - sthala', 'शरणस्थल', 0.828),\n",
       " ('Quantum', 'क़्वान्टम', 0.667),\n",
       " ('Landrace', 'लार्ज', 0.615),\n",
       " ('Rope - Marker', 'रोपमार्कर', 0.667),\n",
       " ('Many', 'समय', 0.6),\n",
       " ('Kusana', 'कुषाण', 0.923),\n",
       " ('Launda', 'लौड़ा', 0.833),\n",
       " ('Acivllre', 'चिवल्लरी', 0.667),\n",
       " ('Shri Bhashyam', 'भाष्यम्र', 0.696),\n",
       " ('Agoura', 'अगौरा', 0.833),\n",
       " ('Argentina', 'हैअर्जेटीना', 0.7),\n",
       " ('Ranu', 'रानू', 1.0),\n",
       " ('Tank', 'टैंको', 0.6),\n",
       " ('Thirukkural', 'थिरुक्कुरल', 0.957),\n",
       " ('King Janak', 'जनक', 0.625),\n",
       " ('Jurchen', 'जुरचेन', 0.875),\n",
       " ('Sisi', 'किसी', 0.75),\n",
       " ('Broadband', 'मुरादाबाद', 0.632),\n",
       " ('Josef', 'योसेफ़', 0.727),\n",
       " ('Lokesvara', 'लोकेश्वर', 0.947),\n",
       " ('Gaya', 'रूपया', 0.6),\n",
       " ('Dhara', 'धारा', 1.0),\n",
       " ('Banta', 'बैठा', 0.727),\n",
       " ('Al-Balad', 'अलबलद', 0.824),\n",
       " ('Karfectar', 'कार्फेक्टर', 0.7),\n",
       " ('Vidino', 'विडिनों', 0.923),\n",
       " ('Africa', 'अफ़्रीक', 0.833),\n",
       " ('Ripping', 'रिपिंग', 0.714),\n",
       " ('Conran', 'कोरण', 0.667),\n",
       " ('Gnome', 'गनोम', 0.727),\n",
       " ('Pather', 'पथेर', 0.923),\n",
       " ('Leman', 'लेमां', 0.8),\n",
       " ('Kapinjala', 'कपिंजल', 0.889),\n",
       " ('Drachma', 'ड्राचमा', 0.933),\n",
       " ('Costa', 'लाओस', 0.6),\n",
       " ('Russia', 'रुस', 0.8),\n",
       " ('Historical', 'हिस्टोरिकल', 0.857),\n",
       " ('Asvina', 'अश्विन', 0.923),\n",
       " ('Qaeda', 'सद्र', 0.6),\n",
       " ('Navyottar', 'नव्योत्तर', 0.947),\n",
       " ('Mugdha', 'मुग्धा', 1.0),\n",
       " ('Madhusudan', 'महान', 0.625),\n",
       " ('Cholamandalam', 'मंडलम', 0.636),\n",
       " ('Bhatta', 'बार', 0.6),\n",
       " ('Glendower', 'ग्लेनडोवर', 0.7),\n",
       " ('Carnival', 'कार्नावालेस', 0.632),\n",
       " ('Shalok', 'श्लोक', 0.833),\n",
       " ('Dhimmi', 'धिम्माह', 0.714),\n",
       " ('Himalayan', 'हिमालच', 0.778),\n",
       " ('Nazir', 'इनकी', 0.6),\n",
       " ('Kapurush', 'कापुरुष', 0.941),\n",
       " ('Jindrahiya', 'जिन्द्राहिया', 1.0),\n",
       " ('Carlsen', 'कार्लसन', 0.625),\n",
       " ('Switcher', 'स्विचर', 0.625),\n",
       " ('Manjiri', 'मंजरी', 0.714),\n",
       " ('Chawla', 'शामिल', 0.615),\n",
       " ('Malibu', 'मलिबू', 1.0),\n",
       " ('Kooch', 'कूच', 0.6),\n",
       " ('Veera Charita', 'चरित्रम्', 0.636),\n",
       " ('Siligudi', 'सिलीगुडी', 1.0),\n",
       " ('Slagore', 'सर्वे', 0.667),\n",
       " ('Khatta', 'कर', 0.6),\n",
       " ('Shuklayajuved', 'शुक्लयजुर्वेद', 0.929),\n",
       " ('Cata', 'काटानो', 0.6),\n",
       " ('Baradasun - dari', 'वरदासुन्दरी', 0.828),\n",
       " ('Thee', 'तूझे', 0.667),\n",
       " ('kakanl', 'काकणी', 0.833),\n",
       " ('Mandayam', 'मंडयम', 0.824),\n",
       " ('Bullet', 'बुलेट', 0.833),\n",
       " ('Influenza', 'इन्फ़्लुएन्ज़ा', 1.0),\n",
       " ('Grus', 'ग्रस', 0.667),\n",
       " ('Frank', 'इराक', 0.6),\n",
       " ('Mandell', 'मण्डेला', 0.857),\n",
       " ('Unable', 'उनके', 0.727),\n",
       " ('Adhipati', 'अधिपति', 1.0),\n",
       " ('Meit', 'मैती', 0.667),\n",
       " ('Pangaea', 'पहले', 0.615),\n",
       " ('Nadu', 'नौंवी', 0.6),\n",
       " ('Millimeter', 'मिलिमीटर', 0.7),\n",
       " ('Sardar', 'सारे', 0.6),\n",
       " ('Plankalk', 'प्लंकल्कुल', 0.737),\n",
       " ('Olhovskiy', 'ओल्हॉफस्की', 0.6),\n",
       " ('Hearn', 'हियर्न', 0.667),\n",
       " ('Audio-Video', 'ऑडियोवीडियो', 0.636),\n",
       " ('Issyk', 'इसिक', 0.6),\n",
       " ('Vincent', 'विन्सेट', 0.714),\n",
       " ('Bhalchandra', 'भालचन्द्र', 0.957),\n",
       " ('Chhatrapti', 'छत्रपति', 0.9),\n",
       " ('Muhamma', 'हमारे', 0.615),\n",
       " ('Badkhal', 'बड़खल', 0.824),\n",
       " ('Kodaikanal', 'कोडाईकनाल', 0.952),\n",
       " ('Ashern', 'आशेर्न', 0.923),\n",
       " ('Emir', 'एमीर', 0.889),\n",
       " ('Clean', 'लेखन', 0.667),\n",
       " ('Turn', 'तौर', 0.667),\n",
       " ('Sekhar', 'नेहरू', 0.667),\n",
       " ('Bagharra', 'बधर्रा', 0.875),\n",
       " ('lora', 'लोरा', 1.0),\n",
       " ('Mandir', 'मंदि', 0.727),\n",
       " ('Benjarong', 'बेंजारोंग', 0.737),\n",
       " ('Adana', 'आस्ताना', 0.727),\n",
       " ('Behead', 'जेहाद', 0.667),\n",
       " ('Homs', 'होम्स', 0.889),\n",
       " ('Assyrian', 'अश्शूर', 0.625),\n",
       " ('Basava', 'पसंद', 0.615),\n",
       " ('Shreevastav', 'श्रीवास्तव', 0.818),\n",
       " ('Rama', 'करना', 0.6),\n",
       " ('Handvu', 'हांडवो', 0.615),\n",
       " ('Nandi', 'नंदि', 0.8),\n",
       " ('Elphinstone', 'एलफिस्टन', 0.727),\n",
       " ('Gosport', 'गॉसापोर्ट', 0.706),\n",
       " ('Test', 'टेस्ट', 0.889),\n",
       " ('Tissue', 'टिश्यू', 0.667),\n",
       " ('Schaffhausen', 'शाफ़हाउसन', 0.75),\n",
       " ('Kumar Jain', 'कुमार', 0.75),\n",
       " ('Dhauliganga', 'धौलीगंगा', 0.909),\n",
       " ('Valabhacharya', 'वल्लभाचार्य।', 0.929),\n",
       " ('Khan', 'खण्ड', 0.8),\n",
       " ('Sujit', 'सुजित', 0.909),\n",
       " ('Jarikondalampatty', 'जरीकोंडलमपट्टी', 0.857),\n",
       " ('Khanij', 'खनिज', 0.923),\n",
       " ('Sibasagar', 'शिवसागर', 0.8),\n",
       " ('Shastri', 'शासित', 0.714),\n",
       " ('Aurillac', 'आरिलाक', 0.667),\n",
       " ('grantha', 'पुराण', 0.615),\n",
       " ('Atomic', 'एटोमिक', 0.615),\n",
       " ('Batanjal', 'पतंजलि', 0.706),\n",
       " ('Premamathi', 'प्रेममती', 0.947),\n",
       " ('Dhirapur', 'धिरापुर', 0.941),\n",
       " ('Sikhism', 'सिक्खों', 0.714),\n",
       " ('Vladikavkaz', 'व्लादिकाव्काज', 0.87),\n",
       " ('Prakashika', 'प्रकाशिका', 1.0),\n",
       " ('Kankali', 'कनकलि', 0.933),\n",
       " ('Shri Bardhan', 'वर्धन', 0.6),\n",
       " ('Rani-Ki-Vav', 'रानीकीवाव', 0.857),\n",
       " ('History', 'हिस्ट्रीऑफ्', 0.625),\n",
       " ('Vijay Singh', 'जयसिंह', 0.6),\n",
       " ('Prabhakaran Nair', 'प्रभाकरण', 0.857),\n",
       " ('Bhojpuri Song', 'भोजपुरी', 0.727),\n",
       " ('Malati - Madhava', 'मालतीमाधव', 0.897),\n",
       " ('Meladom', 'मेलादान', 0.667),\n",
       " ('Khudd', 'खुड्ड', 0.909),\n",
       " ('Bastille', 'बैसटिले', 0.824),\n",
       " ('Shri Adhir', 'अधीर', 0.625),\n",
       " ('Tagged', 'टैगेड', 0.769),\n",
       " ('Vijender', 'विजेंदर', 0.706),\n",
       " ('Coldstream', 'कोल्डस्ट्रीम', 0.667),\n",
       " ('Tuvalu', 'तुवालु', 1.0),\n",
       " ('Ashura', 'आशूरा', 1.0),\n",
       " ('hotel', 'होटल', 0.727),\n",
       " ('swasthIndia', 'स्वस्थ', 0.667),\n",
       " ('Khusrau', 'ख़ुसरू', 0.769),\n",
       " ('Tirana', 'टिराना', 1.0),\n",
       " ('Cardiac', 'कार्डीयाक', 0.625),\n",
       " ('Sobhraj Hassaram', 'सभाजोसींगार', 0.6),\n",
       " ('KChart', 'केचार्ट', 0.857),\n",
       " ('Sulabh', 'सुलभ', 0.923),\n",
       " ('Binding', 'बाइडिंग', 0.667),\n",
       " ('Chartered', 'चार्टड', 0.706),\n",
       " ('Maharaj', 'आचार्य', 0.714),\n",
       " ('thymine', 'थायमीन', 0.75),\n",
       " ('Maruthi', 'हमारी', 0.615),\n",
       " ('Dhekial', 'ढेकियान', 0.75),\n",
       " ('Keshav Vitthal', 'केशवसुत', 0.64),\n",
       " ('Jacob', 'जब', 0.667),\n",
       " ('Abdi', 'अब्दी', 1.0),\n",
       " ('Koshambi', 'कौशम्बी', 0.824),\n",
       " ('Zahir Shah', 'जाहिर', 0.625),\n",
       " ('Coartem', 'कोआर्टम', 0.667),\n",
       " ('Al-Hashr', 'अलहश्र', 0.824),\n",
       " ('mexitli', 'मेक्सिटली', 0.75),\n",
       " ('Pasighat', 'पासीघाट', 0.941),\n",
       " ('Naidu', 'नायड़ु', 0.667),\n",
       " ('Charlotte', 'चार्लोट', 0.824),\n",
       " ('Karkare', 'करकरें', 0.875),\n",
       " ('Bijeshwar', 'बिजेश्वर', 0.842),\n",
       " ('Bhanbhane', 'भन्भने', 1.0),\n",
       " ('Johann', 'जोहान्न', 0.923),\n",
       " ('Sekhon', 'सेखो', 0.909),\n",
       " ('Mathura', 'मध्य', 0.615),\n",
       " ('Buddha', 'बुद्घ', 0.833),\n",
       " ('Nirman', 'नमन', 0.667),\n",
       " ('Jagannalha', 'जगन्नाथ', 0.9),\n",
       " ('Sant Singh', 'संतसिंह', 0.6),\n",
       " ('Teng', 'तेंग', 0.667),\n",
       " ('Kama', 'कामना', 0.8),\n",
       " ('Negritto', 'नैग्रीटो', 0.75),\n",
       " ('Satyapriya', 'सत्यप्रिय', 1.0),\n",
       " ('Manikya', 'आंजनेय', 0.667),\n",
       " ('Giridih', 'गिरीडीह', 0.933),\n",
       " ('Ibrahim', 'रखी', 0.667),\n",
       " ('Mall', 'मल्ल', 0.889),\n",
       " ('Watershed', 'वाटरशेड', 0.7),\n",
       " ('Karima', 'करना।', 0.615),\n",
       " ('Sambapura', 'संबपुर', 1.0),\n",
       " ('Utram', 'उत्तरा', 0.727),\n",
       " ('Shore', 'सोते', 0.667),\n",
       " ('alumina', 'ऐलुमिना।', 0.875),\n",
       " ('Ranji', 'रणजी', 0.909),\n",
       " ('Kalaripayatt', 'कलारीपयत्त', 0.96),\n",
       " ('Pandit', 'पण्डा', 0.727),\n",
       " ('Matter', 'मैटर', 0.615),\n",
       " ('Boomani', 'बूमनी', 0.769),\n",
       " ('Rabah', 'अरब', 0.8),\n",
       " ('Pochampad', 'पोचमपाड', 0.9),\n",
       " ('Stacked', 'स्टैक', 0.615),\n",
       " ('Canchipur', 'कांचीपुर', 0.737),\n",
       " ('Part', 'करती', 0.6),\n",
       " ('Rama', 'समूल', 0.6),\n",
       " ('Aparta', 'अपारता', 0.923),\n",
       " ('Bhavan', 'बढ़ावा', 0.714),\n",
       " ('April', 'गर्इ', 0.667),\n",
       " ('Aranmula', 'आरन्मुला', 1.0),\n",
       " ('Nunavut', 'नूनावट', 0.8),\n",
       " ('Cambodian', 'कम्बोडियन', 0.8),\n",
       " ('Chandiprasad', 'चंडीप्रसाद', 0.88),\n",
       " ('Vayu - Pwana', 'वायुपुराण', 0.727),\n",
       " ('Kokashastra', 'कोकशास्त्र', 1.0),\n",
       " ('Palitana', 'पलिताना', 1.0),\n",
       " (\"Prem Chand'\", 'प्रेमचन्द', 0.818),\n",
       " ('Saudi Arabia', 'अधिकार', 0.6),\n",
       " ('Bulgaria', 'बल्गारिया', 0.824),\n",
       " ('Espana', 'स्पेन', 0.727),\n",
       " ('Agnew', 'बने', 0.667),\n",
       " ('Beejat', 'बीजट', 0.667),\n",
       " ('Boaco', 'बोआको', 0.8),\n",
       " ('Gobichettipalayam', 'गोबिचेट्टिपलयम', 0.971),\n",
       " ('Samar', 'सामरी', 0.909),\n",
       " ('Naqvi', 'नक़वी', 0.909),\n",
       " ('Theo', 'थीयो', 0.667),\n",
       " ('Raga', 'नरह', 0.6),\n",
       " ('Trainload', 'ट्रेनलोड', 0.667),\n",
       " ('Rohanta', 'रोहंत', 0.857),\n",
       " ('Ghaziabad', 'गाज़ियाबाद', 0.842),\n",
       " ('Padmanabhasvami', 'पदनाथस्वामी', 0.897),\n",
       " ('Casaca', 'कसाका', 0.667),\n",
       " ('Radha', 'कथा', 0.6),\n",
       " ('Tel Aviv', 'तेल', 0.667),\n",
       " ('arjan dev', 'अर्जन', 0.667),\n",
       " ('Lego', 'लेगो', 1.0),\n",
       " ('Guria', 'और', 0.667),\n",
       " ('Kerouac', 'केरुयक', 0.667),\n",
       " ('Shivaraj', 'शिवराज', 0.941),\n",
       " ('Magam', 'जंगलों', 0.615),\n",
       " ('RAM Rupkriti', 'रूपाकृति', 0.727),\n",
       " ('Shastra', 'शताब्दी', 0.667),\n",
       " ('Stuart', 'स्टुअर्ट', 0.923),\n",
       " ('Priyamvada', 'प्रियवंदा', 0.9),\n",
       " ('Trumpet', 'ट्रम्पेट', 0.8),\n",
       " ('Ibne', 'इबने', 0.889),\n",
       " ('Guajira', 'गुआजिरा', 1.0),\n",
       " ('Yazdajtrd', 'यज़्दजिर्द', 0.842),\n",
       " ('Bohai', 'बोहाई', 1.0),\n",
       " ('Printed', 'प्रिन्टड', 0.8),\n",
       " ('Saramento', 'सैक्रामेंटो', 0.8),\n",
       " ('Mantar', 'कनॉट', 0.615),\n",
       " ('Tinkathia', 'तिनकटिया', 0.842),\n",
       " ('Karhade', 'कर्हादे', 1.0),\n",
       " ('Pawan', 'पवनकी', 0.615),\n",
       " ('Baroda', 'कर', 0.6),\n",
       " ('Chauhanji', 'चौहान', 0.824),\n",
       " ('Bandopadhyay', 'बंदोपाध्याय', 0.88),\n",
       " ('Salempur', 'सलेमपुर', 0.889),\n",
       " ('Agomoni', 'अगोमोनी', 1.0),\n",
       " ('Maps', 'मैप्स्', 0.889),\n",
       " ('Mayaram', 'मायाराम', 0.933),\n",
       " ('Duraka', 'द्वारका', 0.769),\n",
       " ('Macerata', 'मासेरटा', 0.875),\n",
       " ('Assure', 'और', 0.6),\n",
       " ('Muhammad', 'शाम', 0.615),\n",
       " ('Poorna', 'पूर्ण', 0.727),\n",
       " ('Rasa', 'दास', 0.75),\n",
       " ('Abergavenny', 'एबर्गावेनी', 0.667),\n",
       " ('Koran', 'क्रम', 0.6),\n",
       " ('Victoria', 'विक्टोरिय', 0.824),\n",
       " ('Moldovan Leu', 'मोलदोवियाई', 0.609),\n",
       " ('Bera', 'बेरा', 1.0),\n",
       " ('Wathba', 'वह', 0.6),\n",
       " ('Email', 'महिला', 0.727),\n",
       " ('Brahmin', 'ब्रह्माण', 0.8),\n",
       " ('Sanjiva', 'संजीव', 0.857),\n",
       " ('Tissue', 'टीश्यू', 0.667),\n",
       " ('karet krait', 'करैत', 0.667),\n",
       " ('Maha Bodhi', 'महाबोधि', 0.947),\n",
       " ('Jamdoli', 'जामड़ोली', 0.875),\n",
       " ('Saha', 'अच्छा', 0.6),\n",
       " ('Dark', 'कॉर्क', 0.6),\n",
       " ('Khekiho', 'खेकिहो', 1.0),\n",
       " ('Brahmaputra Board', 'ब्रहृमपुत्र', 0.71),\n",
       " ('Konrote', 'कोनरोटे', 0.933),\n",
       " ('Haramosh', 'हरामोश', 0.941),\n",
       " ('Samir', 'सकें', 0.6),\n",
       " ('Atmnirbhar', 'आत्मनिर्भर', 0.909),\n",
       " ('Iskko', 'इसको', 0.8),\n",
       " ('Pata', 'पहली', 0.6),\n",
       " ('Dhenki', 'ढेंकी', 0.833),\n",
       " ('Basilica', 'बेसिलिका', 0.75),\n",
       " ('T. Hingorani', 'हिंगोरानी', 0.762),\n",
       " ('Krishi', 'राशि', 0.727),\n",
       " ('Tondaimandalam', 'तौडैमंडलम', 0.759),\n",
       " ('Loan', 'मिलने', 0.6),\n",
       " ('Zahid', 'जहीद', 0.727),\n",
       " ('lokadharmi', 'लोकधर्मी', 1.0),\n",
       " ('Alacra', 'एलाक्रा', 0.667),\n",
       " ('Kisarati', 'कंसाराति', 0.824),\n",
       " ('Hikamato', 'हिकमतों', 0.941),\n",
       " ('Annalen', 'अन्नालें', 0.857),\n",
       " ('Allahu', 'हाल', 0.6),\n",
       " ('Satyam', 'सत्य', 0.909),\n",
       " ('Mahal', 'ताखा', 0.6),\n",
       " ('Ela Ramesh', 'रमेश', 0.706),\n",
       " ('Lemna', 'लेमना', 0.909),\n",
       " ('Ranmastkhan', 'रणमस्त', 0.8),\n",
       " ('Dwaraka', 'द्वारिका', 0.714),\n",
       " ('Gefitinib', 'एर्लोटिनिब', 0.632),\n",
       " ('Akshapada', 'अक्षपाद', 1.0),\n",
       " ('Subrabarathi', 'सूर्याभारती', 0.833),\n",
       " ('Trehan', 'त्रेहान', 0.923),\n",
       " ('Berganza', 'बर्गैन्ज़ा', 0.824),\n",
       " ('Shapley', 'शेपले', 0.714),\n",
       " ('Herakal', 'हेराकल्स', 0.875),\n",
       " ('Rempt', 'रेम्प्ट', 0.909),\n",
       " ('Rahgavacharya', 'राघवाचार्य', 0.923),\n",
       " ('Khan', 'महान', 0.6),\n",
       " ('Nandigram', 'नन्दिग्राम', 0.947),\n",
       " ('Tadjik', 'ताजिक', 0.833),\n",
       " ('BunkarMitra', 'बुनकर', 0.737),\n",
       " ('talaq', 'तलाक', 0.727),\n",
       " ('Artemisia', 'आर्टेमीसिआ', 1.0),\n",
       " ('Kaira', 'खैरा', 0.909),\n",
       " ('Intranasal', 'अन्तःनासिक', 0.667),\n",
       " ('Namaz', 'नमाज़', 0.909),\n",
       " ('Zenelaj', 'ज़ेनेलाज', 0.933),\n",
       " ('Bharatha', 'बाहर', 0.714),\n",
       " ('Jnanakosha', 'ज्ञानकोश', 0.952),\n",
       " ('Tanjaur', 'तंजौर', 0.8),\n",
       " ('Gaza', 'गया', 0.75),\n",
       " ('Taystay', 'टॉलस्टॉय', 0.667),\n",
       " ('Blantyre', 'ब्लांटायर', 0.667),\n",
       " ('Ottawa', 'टाला', 0.6),\n",
       " ('Sanchar', 'संचार', 0.8),\n",
       " ('Sukhananda', 'सुखानन्द', 1.0),\n",
       " ('Ahluwalia', 'आहलुवालिया', 0.8),\n",
       " ('B. M. Srikantayya', 'श्रीकंठय्य', 0.667),\n",
       " ('Matej', 'मातेज', 0.909),\n",
       " ('Parna', 'पर्न', 1.0),\n",
       " ('Ummaid', 'उम्मेद', 0.667),\n",
       " ('Devo', 'देवो', 1.0),\n",
       " ('Jordan', 'जॉडन', 0.615),\n",
       " ('Nagpal', 'नागपाल', 0.857),\n",
       " ('jetsam', 'देता', 0.6),\n",
       " ('Sundergarh', 'सुन्दरगड़', 0.636),\n",
       " ('Chandragupta', 'चन्द्रगुप्त', 1.0),\n",
       " ('Raju', 'राजु', 1.0),\n",
       " ('Ranganathananda', 'रंगनाथानन्द', 0.933),\n",
       " ('Dopayan', 'द्वैपायन', 0.706),\n",
       " ('Moti Mardan', 'मरदान', 0.632),\n",
       " ('Anuvadaksh', 'अनुवादक', 0.842),\n",
       " ('Salaam', 'अससलाम', 0.667),\n",
       " ('Turbulent', 'टर्बुलेंट', 0.737),\n",
       " ('Satan', 'शक़', 0.6),\n",
       " ('Chaura', 'और', 0.8),\n",
       " ('Jujuy', 'जुजुए', 0.8),\n",
       " ('Pieter', 'पीटर', 0.667),\n",
       " ('Lakshat', 'लक्षत', 0.933),\n",
       " ('Also', 'नस्लों', 0.6),\n",
       " ('Deck', 'डेक', 0.75),\n",
       " ('Picchu', 'पिच्चू', 0.923),\n",
       " ('Nicki', 'निकी', 0.889),\n",
       " ('Mirbeau', 'मिर्बो', 0.667),\n",
       " ('gorkha king', 'गोरखा', 0.667),\n",
       " ('Khotan', 'खोतान', 0.923),\n",
       " ('Malayala', 'मलयाला', 1.0),\n",
       " ('Katari', 'कतार', 0.833),\n",
       " ('Taiyuan', 'तईयुआन', 0.933),\n",
       " ('Utpakd', 'उत्पाकद', 0.857),\n",
       " ('Operation', 'प्रति', 0.714),\n",
       " ('Shukran', 'शुक्रन', 0.933),\n",
       " ('Quarto', 'क्वार्टो', 0.667),\n",
       " ('Boston', 'बोस्तां', 0.667),\n",
       " ('Jayasimha', 'सिंह', 0.714),\n",
       " ('Kardar', 'कर', 0.8),\n",
       " ('Panjal', 'फौज', 0.667),\n",
       " ('Sassanian', 'ससानियत', 0.737),\n",
       " ('Tab Bar', 'टैब', 0.667),\n",
       " ('Muslim', 'मुस्लीम', 0.923),\n",
       " ('Arati', 'आरती', 1.0),\n",
       " ('Trinidadian', 'त्रिनिदादियन', 0.917),\n",
       " ('Nematode', 'नेमाटोड', 0.875),\n",
       " ('Ali Bilgrami', 'बिलग्रामी', 0.762),\n",
       " ('Ramsharan', 'रामशरण', 0.9),\n",
       " ('Torwali', 'तोरवाली', 0.8),\n",
       " ('Makhan', 'मक्खण', 0.857),\n",
       " ('Sharmishta', 'शर्मिष्टा', 1.0),\n",
       " ('Jagadesh', 'जगदीश', 0.824),\n",
       " ('Nandi,', 'नंदी', 0.727),\n",
       " ('Infantry', 'इन्फ़ेन्ट्री', 0.75),\n",
       " ('Nageri', 'नगेड़ी', 0.769),\n",
       " ('Rambihari', 'रासबिहारी', 0.842),\n",
       " ('Geraldine', 'गेराल्डीन', 0.889),\n",
       " ('Praia', 'पराइबा', 0.833),\n",
       " ...]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_pairs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f325cd91-9d43-49cc-8366-3c1690f883c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total aligned pairs:  122092\n",
      "Unique English names:  74648\n",
      "\n",
      "Top 15 most frequent English names:\n",
      "India 406\n",
      "State 164\n",
      "Sabha 161\n",
      "Rama 150\n",
      "Asia 150\n",
      "Bhavan 117\n",
      "China 117\n",
      "Shah 108\n",
      "Allah 107\n",
      "Khan 95\n",
      "Chandra 86\n",
      "Islam 77\n",
      "Shiva 72\n",
      "Arabia 71\n",
      "Chairman 68\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "with open(\"data/processed/aligned_pairs_full.json\", encoding = \"utf-8\") as f:\n",
    "    pairs = json.load(f)\n",
    "\n",
    "english_names = [en for en, _, _ in pairs]\n",
    "\n",
    "print(\"Total aligned pairs: \", len(pairs))\n",
    "print(\"Unique English names: \", len(set(english_names)))\n",
    "\n",
    "print(\"\\nTop 15 most frequent English names:\")\n",
    "for name, count in Counter(english_names).most_common(15):\n",
    "    print(name, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37efe2f-ad74-4ec2-ac5c-8971769e6ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD ALIGNED PAIRS AND GROUP BY ENGLISH NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4fd163fa-8f06-44b9-8a26-06d4a8a6e2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique English names: 74490\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "with open(\"data/processed/aligned_pairs_full.json\", encoding = \"utf-8\") as f:\n",
    "    aligned_pairs = json.load(f)\n",
    "\n",
    "name_groups = defaultdict(list)\n",
    "\n",
    "for en, hi, score in aligned_pairs:\n",
    "    clean_en = en.strip()\n",
    "    if \"/\" in clean_en:\n",
    "        continue\n",
    "    name_groups[clean_en].append(hi)\n",
    "\n",
    "print(f\"Total unique English names: {len(name_groups)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d484926-b151-4b80-9d87-ca31759905e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROMANIZE HINDI VARIANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "237387a5-507c-47f8-b7c6-babef3028621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from indic_transliteration import sanscript\n",
    "from indic_transliteration.sanscript import transliterate\n",
    "\n",
    "def romanize_hi(word):\n",
    "    try:\n",
    "        return transliterate(word, sanscript.DEVANAGARI, sanscript.ITRANS)\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ae6c17-db32-4b1b-820a-37b2878ba813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLUSTER HINDI VARIANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e861b69b-a016-48f2-83e6-ab13fde59661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similarity(a,b):\n",
    "    return SequenceMatcher(None, a.lower(), b.lower()).ratio()\n",
    "\n",
    "def cluster_variants(hi_variants, threshold = 0.7):\n",
    "    clusters = []\n",
    "\n",
    "    for word in hi_variants:\n",
    "        roman = romanize_hi(word)\n",
    "        placed = False\n",
    "\n",
    "        for cluster in clusters:\n",
    "            rep_roman = cluster[\"roman\"]\n",
    "            if similarity(roman, rep_roman) >= threshold:\n",
    "                cluster[\"variants\"].append(word)\n",
    "                placed = True\n",
    "                break\n",
    "\n",
    "        if not placed:\n",
    "            clusters.append({\n",
    "                \"canonical\": word,\n",
    "                \"roman\": roman,\n",
    "                \"variants\": [word]\n",
    "            })\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04191105-ac52-4a95-80bd-443e12577296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLY CLUSTERING TO ALL NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c74ab5e-aa85-4581-8278-e4812604fb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BAD_ENGLISH = {\n",
    "    \"this\", \"that\", \"these\", \"those\", \n",
    "    \"data\", \"report\", \"name\", \"set\",\n",
    "    \"get\", \"add\", \"remove\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db9340a4-c7f1-40cd-bac2-7250467982d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BAD_ENGLISH.update({\n",
    "    \"american\", \"fast\", \"slow\", \"new\", \"old\", \"good\", \"bad\",\n",
    "    \"open\", \"close\", \"high\", \"low\", \"western\", \"eastern\", \n",
    "    \"northern\", \"southern\", \"central\", \"global\", \"local\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28b700fe-f8f3-43d0-b65e-6024ce6db344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def looks_like_translation(en, hi):\n",
    "    \"\"\"\n",
    "    Returns true if hindi word is likely a semantic translation\n",
    "    rather than a phonetic transliteration.\n",
    "    \"\"\"\n",
    "    hi_roman = romanize_hi(hi)\n",
    "    if len(hi_roman) <= 3 and len(en) >= 4:\n",
    "        return True\n",
    "    if abs(len(en) - len(hi_roman)) > 4:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_native_hindi_translation(hi_word):\n",
    "    \"\"\"\n",
    "    Detects short native Hindi words likely to be translations\n",
    "    rather than transliterations.\n",
    "    \"\"\"\n",
    "    return len(hi_word) <= 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93153b2b-7cdd-42af-963c-cc71ab21c952",
   "metadata": {},
   "outputs": [],
   "source": [
    "canonical_clusters = {}\n",
    "\n",
    "for en_name, hi_variants in name_groups.items():\n",
    "\n",
    "    # Clean & normalize\n",
    "    unique_variants = list(\n",
    "        set(normalize_hindi(v) for v in hi_variants if normalize_hindi(v))\n",
    "    )\n",
    "\n",
    "    if not unique_variants:\n",
    "        continue\n",
    "\n",
    "    clusters = cluster_variants(unique_variants)\n",
    "    final_clusters = []\n",
    "\n",
    "    for cluster in clusters:\n",
    "        variants = cluster[\"variants\"]\n",
    "\n",
    "        # Step 1: remove clear translations early\n",
    "        phonetic_variants = [\n",
    "            v for v in variants\n",
    "            if similarity(en_name, romanize_hi(v)) >= 0.65\n",
    "            and not looks_like_translation(en_name, v)\n",
    "            and not is_native_hindi_translation(v)\n",
    "        ]\n",
    "\n",
    "        # Step 2: fallback ONLY if nothing survived\n",
    "        if phonetic_variants:\n",
    "            candidates = phonetic_variants\n",
    "        else:\n",
    "            candidates = sorted(\n",
    "                variants,\n",
    "                key=lambda v: similarity(en_name, romanize_hi(v)),\n",
    "                reverse=True\n",
    "            )[:1]\n",
    "\n",
    "        # Step 3: choose canonical\n",
    "        canonical = min(\n",
    "            candidates,\n",
    "            key=lambda v: (\n",
    "                -similarity(en_name, romanize_hi(v)),\n",
    "                len(v)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        final_clusters.append({\n",
    "            \"canonical\": canonical,\n",
    "            \"variants\": variants\n",
    "        })\n",
    "        \n",
    "    if not final_clusters:\n",
    "        continue\n",
    "        \n",
    "    canonical_clusters[en_name] = final_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6410e9c-7880-4d97-8dec-144934b40efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da200fce-3ac8-4c1a-8ea5-649af98b4432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " English Name: Scoring\n",
      "  Canonical: स्कोरिंग\n",
      "  Variants: ['स्कोरिंग']\n",
      "\n",
      " English Name: Binding\n",
      "  Canonical: बाइंडिंग\n",
      "  Variants: ['बाइंडिंग']\n",
      "\n",
      " English Name: Camera\n",
      "  Canonical: कैमरा\n",
      "  Variants: ['कैमरा']\n",
      "\n",
      " English Name: Radio\n",
      "  Canonical: रेडियो\n",
      "  Variants: ['रेडियो']\n",
      "\n",
      " English Name: Transcode\n",
      "  Canonical: ट्रांसकोड\n",
      "  Variants: ['ट्रांसकोड']\n"
     ]
    }
   ],
   "source": [
    "for en, clusters in list(canonical_clusters.items())[:5]:\n",
    "    print(f\"\\n English Name: {en}\")\n",
    "    for c in clusters:\n",
    "        print(\"  Canonical:\", c[\"canonical\"])\n",
    "        print(\"  Variants:\", c[\"variants\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c96f71-6b4b-4acd-bd81-7a30ef939490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILTERED IN VSCODE USING FILE filter_aligned_pairs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311d26d6-33b8-49de-9199-7d56d957bdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECKING aligned_pairs_filtered.json file for other transliteration issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56048302-c184-45dc-93b6-2a9b630d9693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91a2317-430f-49fa-8ed6-f09ae4c5c8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "05b08859-0b41-45f0-bf4c-650c96e7b373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Panchal', 'पांचाल', 0.8]\n",
      "['Barrackpur', 'बराकपुर', 0.8]\n",
      "['Iqamat', 'क़यामत', 0.714]\n",
      "['Socialist', 'सोशालिस्ट', 0.737]\n",
      "['Brush', 'ब्रश', 0.727]\n",
      "['Sambhav', 'संभव', 0.933]\n",
      "['Krishnamoorthi', 'कृष्णमूर्ति', 0.815]\n",
      "['Sai', 'साही', 0.857]\n",
      "['Mark Twain', 'मार्कट्वेन', 0.6]\n",
      "['Norman', 'नारमन', 0.714]\n",
      "['Chitrakoot', 'चित्रकूट', 0.8]\n",
      "['Chhau', 'चौकी', 0.727]\n",
      "['Gurtu', 'गुर्टु', 1.0]\n",
      "['Prachar', 'प्रचार', 0.933]\n",
      "['Tilaya', 'तिलाया', 1.0]\n",
      "['Halva', 'हलवाह', 0.769]\n",
      "['Gune', 'गुणे', 1.0]\n",
      "['Ravindran', 'रवीन्द्रन', 0.947]\n",
      "['Acarya', 'आचार्यो', 0.769]\n",
      "['Iqbal', 'इक़बाल', 0.833]\n",
      "['Surjit', 'सुरजीत', 0.857]\n",
      "['Syiemlieh', 'सिम्लिह', 0.75]\n",
      "['Erivan', 'जेरेवन', 0.714]\n",
      "['Krishna Avatar', 'कृष्णावतार', 0.857]\n",
      "['Dione', 'डैओने', 0.909]\n",
      "['Farkka', 'फरक्का', 0.714]\n",
      "['Testament', 'न्यूटेस्टामेन्ट', 0.818]\n",
      "['Ramendrasundar', 'रामेंद्रसुंदर', 0.828]\n",
      "['Pattnayak', 'पटनायक', 0.842]\n",
      "['Sandani', 'सांडनी', 0.857]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "with open(\"data/processed/aligned_pairs_filtered.json\", encoding = \"utf-8\") as f:\n",
    "    pairs = json.load(f)\n",
    "\n",
    "for p in random.sample(pairs, 30):\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf72231-d9d6-431b-9be9-907761318fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOW CHECKING THE FILE WITH HIGHEST SCORES FOR OTHER TRANSLITERATION ISSUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "09bee2d7-5514-467c-9557-45059aec97cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Valaraju', 'वलराजु', 1.0]\n",
      "['Samayapuram', 'समयपुरम्', 1.0]\n",
      "['Poduval', 'पोडुवाल', 0.933]\n",
      "['Farhan', 'फ़रहान', 0.857]\n",
      "['Latrobe', 'लाट्रोब', 0.857]\n",
      "['Lalitaditya', 'ललितादित्य', 1.0]\n",
      "['Akash', 'आकाश', 0.909]\n",
      "['Chaiyan', 'छैंया', 0.857]\n",
      "['Prabhath', 'प्रभात', 0.875]\n",
      "['Kakavali', 'काकवली', 1.0]\n",
      "['Harp', 'हार्प', 0.889]\n",
      "['Essebsi', 'एसेब्सी', 0.923]\n",
      "['Rohtak', 'रोहतक', 0.857]\n",
      "['Dhania', 'धनिया', 0.923]\n",
      "['Gadiara', 'गडियारा', 0.933]\n",
      "['Arch', 'आर्च', 0.889]\n",
      "['Kapalbhati', 'कपालभाती', 0.952]\n",
      "['Chetanya', 'चेतन्य', 1.0]\n",
      "['Paraguarí', 'पारागुआरी', 0.889]\n",
      "['Amargun', 'अमरगुन', 0.875]\n",
      "['Nimroz', 'निमरोज़', 0.857]\n",
      "['Teprikardr', 'टेपरिकार्डर', 0.87]\n",
      "['Brahmana', 'ब्रह्मा', 0.857]\n",
      "['Rupaniji', 'रुपाणी', 0.857]\n",
      "['Mangueshi', 'मंगुएशी', 0.889]\n",
      "['Krishnadayal', 'कृष्णदयाल', 0.923]\n",
      "['Islamia', 'इस्लामिया', 0.933]\n",
      "['Bhutabali', 'भूतबलि', 1.0]\n",
      "['Bilal', 'बिलाल', 0.909]\n",
      "['Bhatiyari', 'भटियारी', 1.0]\n",
      "['Malti', 'मालती', 0.909]\n",
      "['Mbandaka', 'माबान्दाका', 0.941]\n",
      "['Bhattoji', 'भट्टोजी', 1.0]\n",
      "['Lakshmilahari', 'लक्ष्मीलहरी', 1.0]\n",
      "['Gonasika', 'गोनाशिका', 0.941]\n",
      "['Menmecho', 'मेनमेचो', 0.941]\n",
      "['Upamanyu', 'अपमन्यु', 0.875]\n",
      "['Gyasuddin', 'ग़यासुद्दीन', 0.9]\n",
      "['Japanat', 'जापान', 0.923]\n",
      "['Jamunapari', 'जमुनापरी', 1.0]\n"
     ]
    }
   ],
   "source": [
    "import json, random\n",
    "\n",
    "with open(\"data/processed/aligned_pairs_high_conf.json\", encoding = \"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "for p in random.sample(data, 40):\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "92005bd8-a50e-451c-ab1a-cda2c25b6c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered aligned pairs:  41044\n",
      "Unique english names:  33418\n",
      "Chennai 26\n",
      "Maharashtra 23\n",
      "Mumbai 19\n",
      "Rajasthan 16\n",
      "Kashmir 15\n",
      "Vanuatu 12\n",
      "Hindustani 12\n",
      "Hindi 12\n",
      "Brahma 12\n",
      "Madurai 12\n",
      "Kirgizia 11\n",
      "Visakhapatnam 11\n",
      "Kirghizia 11\n",
      "Brahman 11\n",
      "Bangladesh 10\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "english = [en for en, _, _ in data]\n",
    "\n",
    "print(\"Filtered aligned pairs: \", len(data))\n",
    "print(\"Unique english names: \", len(set(english)))\n",
    "\n",
    "for name, c in Counter(english).most_common(15):\n",
    "    print(name, c)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f9e70d-d78b-49f8-8a38-04b3f12bb77c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (translit)",
   "language": "python",
   "name": "translit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
